#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«å­¦ä¹ /å¿«æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½æ…¢å­¦ä¹ è®­ç»ƒçš„æƒé‡å‚æ•°å’Œå­¦ä¹ è¶…å‚æ•°
2. å®ç°ç¯å¢ƒåˆ†å¸ƒå·®å¼‚åº¦é‡ï¼ˆKLæ•£åº¦ï¼‰
3. å®ç°æ›´æ–°è§¦å‘æ¡ä»¶
4. å®ç°åœ¨çº¿æ›´æ–°æµç¨‹
5. æ”¯æŒåœ¨ä¸åŒç¯å¢ƒä¸‹è¿›è¡Œå¿«æµ‹è¯•
6. æ”¯æŒä¸€é”®æµ‹è¯•è¶…çº§ç¯å¢ƒä¸‹çš„æ‰€æœ‰ç¯å¢ƒ
7. æ”¯æŒè‡ªä¸»æŒ‡å®šåœ¨çº¿å­¦ä¹ è¶…å‚æ•°

å‚è€ƒæ–‡ç« ä¸­çš„å­¦ä¹ æµç¨‹ï¼š
- ç¯å¢ƒåˆ†å¸ƒå·®å¼‚åº¦é‡ï¼šKLæ•£åº¦
- æ»‘åŠ¨çª—å£é‡‡æ ·-æ ¸å¯†åº¦ä¼°è®¡
- åŒé‡è§¦å‘æœºåˆ¶ï¼šKLæ•£åº¦é˜ˆå€¼ + æ€§èƒ½æŒ‡æ ‡é˜ˆå€¼
- åœ¨çº¿æ›´æ–°æµç¨‹ï¼šå‚æ•°å¤‡ä»½ â†’ å±€éƒ¨å‚æ•°ä¼˜åŒ– â†’ æ›´æ–°æ•ˆæœéªŒè¯
"""

import os
import sys
import time
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.neighbors import KernelDensity
import json
from datetime import datetime

# å»¶è¿Ÿå¯¼å…¥matplotlibï¼Œä»…åœ¨éœ€è¦æ—¶å¯¼å…¥
def setup_matplotlib():
    """
    è®¾ç½®matplotlibç¯å¢ƒ
    """
    # å¯¼å…¥matplotlib
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
    import matplotlib.pyplot as plt
    return matplotlib, plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
from Scripts.Chapter5.Meta_RL_Engine import MetaRLPolicy
from Scripts.Chapter3.MARL_Engine import device
from Scripts.Chapter5.Env_Ultra import EnvUltra

class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyç±»å‹"""
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        return super(NumpyEncoder, self).default(obj)

class FastAdaptationTrainer:
    """
    å¿«å­¦ä¹ /å¿«æµ‹è¯•è®­ç»ƒå™¨
    """
    def __init__(self, model_path, hyperparams_path=None, custom_hyperparams=None):
        """
        åˆå§‹åŒ–å¿«å­¦ä¹ è®­ç»ƒå™¨
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            hyperparams_path: å¿«å­¦ä¹ è¶…å‚æ•°è·¯å¾„
            custom_hyperparams: è‡ªå®šä¹‰è¶…å‚æ•°
        """
        # ç”Ÿæˆå”¯ä¸€çš„timestampï¼Œç”¨äºæ‰€æœ‰ç»“æœä¿å­˜
        self.timestamp = datetime.now().strftime("%m%d_%H%M%S")
        
        # åŠ è½½æ¨¡å‹
        self.hidden_dim = self._infer_hidden_dim(model_path)
        self.model = MetaRLPolicy(hidden_dim=self.hidden_dim).to(device)
        self.model.load_state_dict(torch.load(model_path, map_location=device))
        self.model.eval()
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
        
        # åŠ è½½è¶…å‚æ•°
        self.hyperparams = self._load_hyperparams(hyperparams_path, custom_hyperparams)
        print(f"âœ… æˆåŠŸåŠ è½½è¶…å‚æ•°")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.hyperparams['lr'])
        self.loss_func = nn.SmoothL1Loss()
        
        # åˆå§‹åŒ–æ»‘åŠ¨çª—å£
        self.window_size = self.hyperparams['window_size']
        self.temp_window = []  # æ¸©åº¦æ»‘åŠ¨çª—å£
        self.power_window = []  # åŠŸç‡éœ€æ±‚æ»‘åŠ¨çª—å£
        
        # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            'power_matching': [],
            'hydrogen_growth': [],
            'soc_fluctuation': []
        }
        
        # åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒåˆ†å¸ƒï¼ˆä»è®­ç»ƒæ•°æ®ä¸­ä¼°è®¡ï¼‰
        self.train_temp_dist = None
        self.train_power_dist = None
        self._estimate_train_distributions()
        
        # åˆå§‹åŒ–å‚æ•°å¤‡ä»½
        self.params_backup = None
        
    def _infer_hidden_dim(self, model_path):
        """
        ä»æ¨¡å‹æ–‡ä»¶ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            hidden_dim: éšè—å±‚ç»´åº¦
        """
        # åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
        state_dict = torch.load(model_path, map_location=device)
        
        # ä»RNNå±‚å‚æ•°ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        for key in state_dict.keys():
            if 'rnn.weight_hh_l0' in key:
                # RNNéšè—å±‚ç»´åº¦æ˜¯weight_hh_l0çš„å½¢çŠ¶[out_features, hidden_size]çš„ç¬¬äºŒä¸ªç»´åº¦
                return state_dict[key].shape[1]
        
        # ä»fc_feature1å±‚å‚æ•°ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        for key in state_dict.keys():
            if 'fc_feature1.weight' in key:
                return state_dict[key].shape[1]
        
        return 512  # é»˜è®¤å€¼
    
    def _load_hyperparams(self, hyperparams_path, custom_hyperparams):
        """
        åŠ è½½è¶…å‚æ•°
        
        Args:
            hyperparams_path: è¶…å‚æ•°æ–‡ä»¶è·¯å¾„
            custom_hyperparams: è‡ªå®šä¹‰è¶…å‚æ•°
        
        Returns:
            åˆå¹¶åçš„è¶…å‚æ•°å­—å…¸
        """
        # é»˜è®¤è¶…å‚æ•°
        default_hyperparams = {
            "lr": 5e-5,
            "gamma": 0.95,
            "hidden_dim": 512,
            "batch_size": 32,
            "update_steps": 10,
            "kl_threshold": 0.3,
            "window_size": 100,
            "kl_weight_temp": 0.5,
            "kl_weight_power": 0.5,
            "power_matching_threshold": 0.9,
            "hydrogen_growth_threshold": 0.01,
            "soc_fluctuation_threshold": 0.08,
            "performance_check_steps": 50,
            "backup_params": True,
            "optimize_all_params": True,
            "validation_steps": 100,
            "success_reward_iterations": 10,
            "kernel_bandwidth_temp": 2.0,
            "kernel_bandwidth_power": 50.0,
            "density_estimation_method": "gaussian",
            "meta_lr": 5e-6,
            "meta_steps": 5,
            "adaptation_steps": 200,
            "performance_recovery_rate": 0.98
        }
        
        # ä»æ–‡ä»¶åŠ è½½è¶…å‚æ•°
        file_hyperparams = {}
        if hyperparams_path and os.path.exists(hyperparams_path):
            with open(hyperparams_path, 'r', encoding='utf-8') as f:
                file_hyperparams = json.load(f)
        
        # åˆå¹¶è¶…å‚æ•°ï¼šé»˜è®¤ â†’ æ–‡ä»¶ â†’ è‡ªå®šä¹‰
        hyperparams = default_hyperparams.copy()
        hyperparams.update(file_hyperparams)
        if custom_hyperparams:
            hyperparams.update(custom_hyperparams)
        
        return hyperparams
    
    def _estimate_train_distributions(self):
        """
        ä¼°è®¡è®­ç»ƒç¯å¢ƒçš„åˆ†å¸ƒ
        """
        # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºè®­ç»ƒç¯å¢ƒåˆ†å¸ƒ
        # å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä»80ç»„è®­ç»ƒåœºæ™¯æ•°æ®ä¸­ä¼°è®¡
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        np.random.seed(42)
        train_temp_data = np.random.normal(25, 5, size=10000)
        train_power_data = np.random.normal(2000, 500, size=10000)
        
        # ä½¿ç”¨æ ¸å¯†åº¦ä¼°è®¡è®­ç»ƒç¯å¢ƒåˆ†å¸ƒ
        self.train_temp_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_temp']
        )
        self.train_temp_dist.fit(train_temp_data.reshape(-1, 1))
        
        self.train_power_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_power']
        )
        self.train_power_dist.fit(train_power_data.reshape(-1, 1))
        
        print(f"âœ… æˆåŠŸä¼°è®¡è®­ç»ƒç¯å¢ƒåˆ†å¸ƒ")
    
    def _update_sliding_window(self, temp, power):
        """
        æ›´æ–°æ»‘åŠ¨çª—å£
        
        Args:
            temp: å½“å‰æ¸©åº¦
            power: å½“å‰åŠŸç‡éœ€æ±‚
        """
        # æ›´æ–°æ¸©åº¦æ»‘åŠ¨çª—å£
        self.temp_window.append(temp)
        if len(self.temp_window) > self.window_size:
            self.temp_window.pop(0)
        
        # æ›´æ–°åŠŸç‡éœ€æ±‚æ»‘åŠ¨çª—å£
        self.power_window.append(power)
        if len(self.power_window) > self.window_size:
            self.power_window.pop(0)
    
    def _estimate_current_distributions(self):
        """
        ä¼°è®¡å½“å‰ç¯å¢ƒçš„åˆ†å¸ƒ
        
        Returns:
            temp_dist: å½“å‰æ¸©åº¦åˆ†å¸ƒ
            power_dist: å½“å‰åŠŸç‡éœ€æ±‚åˆ†å¸ƒ
        """
        if len(self.temp_window) < self.window_size or len(self.power_window) < self.window_size:
            return None, None
        
        # ä¼°è®¡å½“å‰æ¸©åº¦åˆ†å¸ƒ
        temp_data = np.array(self.temp_window).reshape(-1, 1)
        temp_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_temp']
        )
        temp_dist.fit(temp_data)
        
        # ä¼°è®¡å½“å‰åŠŸç‡éœ€æ±‚åˆ†å¸ƒ
        power_data = np.array(self.power_window).reshape(-1, 1)
        power_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_power']
        )
        power_dist.fit(power_data)
        
        return temp_dist, power_dist
    
    def _calculate_kl_divergence(self, p_dist, q_dist, data):
        """
        è®¡ç®—KLæ•£åº¦ D_KL(P||Q)
        
        Args:
            p_dist: å½“å‰åˆ†å¸ƒ
            q_dist: è®­ç»ƒåˆ†å¸ƒ
            data: é‡‡æ ·æ•°æ®
        
        Returns:
            kl_divergence: KLæ•£åº¦å€¼
        """
        if p_dist is None or q_dist is None:
            return 0.0
        
        # è®¡ç®—log P(x) - log Q(x)
        log_p = p_dist.score_samples(data)
        log_q = q_dist.score_samples(data)
        
        # è®¡ç®—KLæ•£åº¦
        kl_divergence = np.mean(log_p - log_q)
        
        return max(0.0, kl_divergence)  # KLæ•£åº¦éè´Ÿ
    
    def _calculate_total_kl(self):
        """
        è®¡ç®—ç»¼åˆKLæ•£åº¦
        
        Returns:
            total_kl: ç»¼åˆKLæ•£åº¦å€¼
        """
        # ä¼°è®¡å½“å‰åˆ†å¸ƒ
        temp_dist, power_dist = self._estimate_current_distributions()
        if temp_dist is None or power_dist is None:
            return 0.0
        
        # å‡†å¤‡æ•°æ®
        temp_data = np.array(self.temp_window).reshape(-1, 1)
        power_data = np.array(self.power_window).reshape(-1, 1)
        
        # è®¡ç®—æ¸©åº¦KLæ•£åº¦
        kl_temp = self._calculate_kl_divergence(temp_dist, self.train_temp_dist, temp_data)
        
        # è®¡ç®—åŠŸç‡éœ€æ±‚KLæ•£åº¦
        kl_power = self._calculate_kl_divergence(power_dist, self.train_power_dist, power_data)
        
        # è®¡ç®—ç»¼åˆKLæ•£åº¦
        total_kl = (self.hyperparams['kl_weight_temp'] * kl_temp + 
                   self.hyperparams['kl_weight_power'] * kl_power)
        
        return total_kl
    
    def _update_performance_metrics(self, power_matching, hydrogen_growth, soc_fluctuation):
        """
        æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        
        Args:
            power_matching: åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
            hydrogen_growth: ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
            soc_fluctuation: é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        """
        # æ›´æ–°åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
        self.performance_metrics['power_matching'].append(power_matching)
        if len(self.performance_metrics['power_matching']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['power_matching'].pop(0)
        
        # æ›´æ–°ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
        self.performance_metrics['hydrogen_growth'].append(hydrogen_growth)
        if len(self.performance_metrics['hydrogen_growth']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['hydrogen_growth'].pop(0)
        
        # æ›´æ–°é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        self.performance_metrics['soc_fluctuation'].append(soc_fluctuation)
        if len(self.performance_metrics['soc_fluctuation']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['soc_fluctuation'].pop(0)
    
    def _reset_sliding_window(self):
        """
        é‡ç½®æ»‘åŠ¨çª—å£
        """
        self.temp_window = []  # æ¸©åº¦æ»‘åŠ¨çª—å£
        self.power_window = []  # åŠŸç‡éœ€æ±‚æ»‘åŠ¨çª—å£
    
    def _reset_performance_metrics(self):
        """
        é‡ç½®æ€§èƒ½æŒ‡æ ‡
        """
        self.performance_metrics = {
            'power_matching': [],
            'hydrogen_growth': [],
            'soc_fluctuation': []
        }
    
    def _check_performance_thresholds(self):
        """
        æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        
        Returns:
            performance_anomaly: æ˜¯å¦å­˜åœ¨æ€§èƒ½å¼‚å¸¸
        """
        # æ£€æŸ¥åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
        if self.performance_metrics['power_matching']:
            avg_power_matching = np.mean(self.performance_metrics['power_matching'])
            if avg_power_matching <= self.hyperparams['power_matching_threshold']:
                return True
        
        # æ£€æŸ¥ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
        if self.performance_metrics['hydrogen_growth']:
            avg_hydrogen_growth = np.mean(self.performance_metrics['hydrogen_growth'])
            if avg_hydrogen_growth >= self.hyperparams['hydrogen_growth_threshold']:
                return True
        
        # æ£€æŸ¥é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        if self.performance_metrics['soc_fluctuation']:
            avg_soc_fluctuation = np.mean(self.performance_metrics['soc_fluctuation'])
            if avg_soc_fluctuation >= self.hyperparams['soc_fluctuation_threshold']:
                return True
        
        return False
    
    def _should_update(self):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ›´æ–°
        
        Returns:
            should_update: æ˜¯å¦åº”è¯¥æ›´æ–°
        """
        # è®¡ç®—ç»¼åˆKLæ•£åº¦
        total_kl = self._calculate_total_kl()
        
        # æ£€æŸ¥KLæ•£åº¦é˜ˆå€¼
        if total_kl < self.hyperparams['kl_threshold']:
            return False
        
        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        performance_anomaly = self._check_performance_thresholds()
        
        return performance_anomaly
    
    def _backup_params(self):
        """
        å¤‡ä»½å½“å‰å‚æ•°
        """
        if self.hyperparams['backup_params']:
            self.params_backup = self.model.state_dict().copy()
            print(f"ğŸ“¦ å‚æ•°å¤‡ä»½å®Œæˆ")
    
    def _restore_params(self):
        """
        æ¢å¤å¤‡ä»½å‚æ•°
        """
        if self.params_backup is not None:
            self.model.load_state_dict(self.params_backup)
            print(f"ğŸ”„ å‚æ•°æ¢å¤å®Œæˆ")
    
    def _optimize_model(self, experiences):
        """
        ä¼˜åŒ–æ¨¡å‹å‚æ•°
        
        Args:
            experiences: ç»éªŒæ•°æ®
        """
        if not experiences:
            return
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # ä¼˜åŒ–æ¨¡å‹
        for _ in range(self.hyperparams['update_steps']):
            for exp in experiences:
                state = exp['state']
                reward = exp['reward']
                
                # æ„å»ºè®¡ç®—å›¾
                state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
                fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
                
                # è®¡ç®—æŸå¤±
                target = torch.tensor(reward, dtype=torch.float32).to(device)
                loss_fc = self.loss_func(fc_action_out, target.expand_as(fc_action_out)) * 1.5
                loss_bat = self.loss_func(bat_action_out, target.expand_as(bat_action_out))
                loss_sc = self.loss_func(sc_action_out, target.expand_as(sc_action_out))
                
                total_loss = loss_fc + loss_bat + loss_sc
                
                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                total_loss.backward()
                self.optimizer.step()
        
        # æ¢å¤æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.eval()
        
        print(f"âš¡ æ¨¡å‹ä¼˜åŒ–å®Œæˆï¼Œæ›´æ–°æ­¥æ•°: {self.hyperparams['update_steps']}")
    
    def _validate_update(self, env, max_steps=100):
        """
        éªŒè¯æ›´æ–°æ•ˆæœ
        
        Args:
            env: éªŒè¯ç¯å¢ƒ
            max_steps: éªŒè¯æ­¥æ•°
        
        Returns:
            update_success: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        state = env.reset()
        total_reward = 0.0
        success_count = 0
        
        for step in range(max_steps):
            # é€‰æ‹©åŠ¨ä½œ
            state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
            fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
            
            # è´ªå©ªé€‰æ‹©åŠ¨ä½œ
            fc_action = torch.argmax(fc_action_out, dim=1).item()
            bat_action = torch.argmax(bat_action_out, dim=1).item()
            sc_action = torch.argmax(sc_action_out, dim=1).item()
            
            action_list = [fc_action, bat_action, sc_action]
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, done, info = env.step(action_list)
            
            total_reward += reward
            state = next_state
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if reward > -100.0:  # å‡è®¾å¥–åŠ±å¤§äº-100ä¸ºæˆåŠŸ
                success_count += 1
            
            if done:
                break
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æˆåŠŸæ¡ä»¶
        success_rate = success_count / max_steps
        update_success = success_rate >= self.hyperparams['performance_recovery_rate']
        
        print(f"âœ… æ›´æ–°éªŒè¯å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.2f}")
        
        return update_success
    
    def test_single_scenario(self, scenario, max_steps=1000, save_results=True, episodes=1):
        """
        æµ‹è¯•å•ä¸ªåœºæ™¯
        
        Args:
            scenario: åœºæ™¯åç§°
            max_steps: æœ€å¤§æµ‹è¯•æ­¥æ•°
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            episodes: æµ‹è¯•å›åˆæ•°
        
        Returns:
            test_results: æµ‹è¯•ç»“æœ
        """
        print(f"\n=== æµ‹è¯•åœºæ™¯: {scenario}, å›åˆæ•°: {episodes} ===")
        
        # è®°å½•æµ‹è¯•å¼€å§‹æ—¶é—´
        test_start_time = time.time()
        
        # åˆå§‹åŒ–æ€»å¥–åŠ±å’Œæ€»æ­¥æ•°
        total_reward = 0.0
        total_steps = 0
        
        # ä¿å­˜æ¯ä¸ªå›åˆçš„ç»“æœ
        all_episode_results = []
        
        for episode in range(episodes):
            print(f"\n--- å›åˆ {episode+1}/{episodes} ---")
            
            # åˆ›å»ºç¯å¢ƒ
            env = EnvUltra(scenario_type=scenario)
            state = env.reset()
            
            # åˆå§‹åŒ–æ•°æ®æ”¶é›†
            episode_results = {
                'scenario': scenario,
                'episode': episode+1,
                'steps': [],
                'rewards': [],
                'power_fc': [],
                'power_bat': [],
                'power_sc': [],
                'load_demand': [],
                'temperature': [],
                'soc_bat': [],
                'soc_sc': [],
                'kl_values': [],
                'step_times': [],
                'decision_times': [],
                'update_duration': [],
                'updates_triggered': 0
            }
        
            # åˆå§‹åŒ–å›åˆç›¸å…³å˜é‡
            episode_total_reward = 0.0
            episode_update_triggered = False
            episode_experiences = []
            episode_update_count = 0
            
            # é‡ç½®æ»‘åŠ¨çª—å£å’Œæ€§èƒ½æŒ‡æ ‡
            self._reset_sliding_window()
            self._reset_performance_metrics()
            
            # å›åˆæµ‹è¯•å¾ªç¯
            for step in range(max_steps):
                # è®°å½•æ­¥éª¤å¼€å§‹æ—¶é—´
                step_start_time = time.time()
                
                # é€‰æ‹©åŠ¨ä½œ - è®°å½•å†³ç­–å¼€å§‹æ—¶é—´
                decision_start_time = time.time()
                
                state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
                fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
                
                # è´ªå©ªé€‰æ‹©åŠ¨ä½œ
                fc_action = torch.argmax(fc_action_out, dim=1).item()
                bat_action = torch.argmax(bat_action_out, dim=1).item()
                sc_action = torch.argmax(sc_action_out, dim=1).item()
                
                action_list = [fc_action, bat_action, sc_action]
                
                # è®°å½•å†³ç­–ç»“æŸæ—¶é—´å¹¶è®¡ç®—å†³ç­–è€—æ—¶
                decision_end_time = time.time()
                decision_duration = decision_end_time - decision_start_time
                episode_results['decision_times'].append(decision_duration)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, info = env.step(action_list)
                
                # æ›´æ–°æ»‘åŠ¨çª—å£
                temp = info['T_amb']
                power_demand = info['P_load']
                self._update_sliding_window(temp, power_demand)
                
                # è®¡ç®—åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
                total_supply = info['P_fc'] + info['P_bat'] + info['P_sc']
                power_matching = min(1.0, total_supply / power_demand) if power_demand > 0 else 1.0
                
                # è®¡ç®—SOCæ³¢åŠ¨å¹…åº¦ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                soc_fluctuation = abs(next_state[5] - state[5])
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                self._update_performance_metrics(power_matching, 0.0, soc_fluctuation)  # ç®€åŒ–è®¡ç®—
                
                # è®¡ç®—ç»¼åˆKLæ•£åº¦
                total_kl = self._calculate_total_kl()
                
                # æ”¶é›†ç»éªŒæ•°æ®
                episode_experiences.append({
                    'state': state,
                    'reward': reward
                })
                
                # é™åˆ¶ç»éªŒæ•°æ®é•¿åº¦
                if len(episode_experiences) > self.hyperparams['batch_size']:
                    episode_experiences.pop(0)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ›´æ–°
                if self._should_update() and not episode_update_triggered:
                    print(f"ğŸš€ è§¦å‘æ›´æ–°ï¼ŒKLæ•£åº¦: {total_kl:.4f}, æ­¥æ•°: {step}")
                    
                    # è®°å½•æ›´æ–°å¼€å§‹æ—¶é—´
                    update_start_time = time.time()
                    
                    # å¤‡ä»½å‚æ•°
                    self._backup_params()
                    
                    # ä¼˜åŒ–æ¨¡å‹
                    self._optimize_model(episode_experiences)
                    
                    # éªŒè¯æ›´æ–°æ•ˆæœ
                    if not self._validate_update(env, self.hyperparams['validation_steps']):
                        # æ¢å¤å¤‡ä»½å‚æ•°
                        self._restore_params()
                    else:
                        episode_update_count += 1
                    
                    # è®°å½•æ›´æ–°ç»“æŸæ—¶é—´
                    update_end_time = time.time()
                    update_duration = update_end_time - update_start_time
                    episode_results['update_duration'].append(update_duration)
                    print(f"â±ï¸  æ›´æ–°è€—æ—¶: {update_duration:.4f}ç§’")
                    
                    episode_update_triggered = True
                
                # æ”¶é›†æµ‹è¯•æ•°æ®
                episode_results['steps'].append(step)
                episode_results['rewards'].append(reward)
                episode_results['power_fc'].append(info['P_fc'])
                episode_results['power_bat'].append(info['P_bat'])
                episode_results['power_sc'].append(info['P_sc'])
                episode_results['load_demand'].append(power_demand)
                episode_results['temperature'].append(temp)
                episode_results['soc_bat'].append(next_state[5])
                episode_results['soc_sc'].append(next_state[6])
                episode_results['kl_values'].append(total_kl)
                
                # è®°å½•æ­¥éª¤ç»“æŸæ—¶é—´
                step_end_time = time.time()
                step_duration = step_end_time - step_start_time
                episode_results['step_times'].append(step_duration)
                
                episode_total_reward += reward
                state = next_state
                
                if done:
                    break
            
            # è®¡ç®—å›åˆç»Ÿè®¡æŒ‡æ ‡
            episode_avg_reward = episode_total_reward / (step + 1) if step > 0 else 0.0
            episode_results['avg_reward'] = episode_avg_reward
            episode_results['total_reward'] = episode_total_reward
            episode_results['total_steps'] = step + 1
            episode_results['updates_triggered'] = episode_update_count
            
            # æ·»åŠ åˆ°æ‰€æœ‰å›åˆç»“æœåˆ—è¡¨
            all_episode_results.append(episode_results)
            
            # æ›´æ–°æ€»å¥–åŠ±å’Œæ€»æ­¥æ•°
            total_reward += episode_total_reward
            total_steps += step + 1
            
            print(f"âœ… å›åˆ {episode+1} å®Œæˆ")
            print(f"   å›åˆå¥–åŠ±: {episode_total_reward:.2f}")
            print(f"   å›åˆå¹³å‡å¥–åŠ±: {episode_avg_reward:.4f}")
            print(f"   å›åˆè§¦å‘æ›´æ–°æ¬¡æ•°: {episode_update_count}")
        
        # è®°å½•æµ‹è¯•ç»“æŸæ—¶é—´
        test_end_time = time.time()
        total_test_duration = test_end_time - test_start_time
        
        # è®¡ç®—æ‰€æœ‰å›åˆçš„ç»Ÿè®¡æŒ‡æ ‡
        overall_avg_reward = total_reward / total_steps if total_steps > 0 else 0.0
        
        # è®¡ç®—è€—æ—¶ç»Ÿè®¡æŒ‡æ ‡
        timing_stats = {
            'total_test_duration': total_test_duration,  # æ€»æµ‹è¯•è€—æ—¶ï¼ˆç§’ï¼‰
            'avg_episode_duration': 0.0,  # å¹³å‡æ¯å›åˆè€—æ—¶ï¼ˆç§’ï¼‰
            'avg_step_duration_ms': 0.0,  # å¹³å‡æ¯æ­¥è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'max_step_duration_ms': 0.0,  # æœ€å¤§å•æ­¥è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'min_step_duration_ms': float('inf'),  # æœ€å°å•æ­¥è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'avg_decision_duration_ms': 0.0,  # å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'max_decision_duration_ms': 0.0,  # æœ€å¤§å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'min_decision_duration_ms': float('inf'),  # æœ€å°å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'total_update_duration_ms': 0.0,  # æ€»æ›´æ–°è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'avg_update_duration_ms': 0.0,  # å¹³å‡æ›´æ–°è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            'update_count': 0  # æ›´æ–°æ€»æ¬¡æ•°
        }
        
        # è®¡ç®—å„å›åˆçš„è€—æ—¶ç»Ÿè®¡
        total_episode_durations = 0.0
        all_step_times = []
        all_decision_times = []
        all_update_times = []
        
        for episode_result in all_episode_results:
            # è®¡ç®—å›åˆè€—æ—¶
            if episode_result['step_times']:
                episode_duration = sum(episode_result['step_times'])
                total_episode_durations += episode_duration
            
            # æ”¶é›†æ‰€æœ‰æ­¥è€—æ—¶
            all_step_times.extend(episode_result['step_times'])
            
            # æ”¶é›†æ‰€æœ‰å†³ç­–è€—æ—¶
            if 'decision_times' in episode_result:
                all_decision_times.extend(episode_result['decision_times'])
            
            # æ”¶é›†æ‰€æœ‰æ›´æ–°è€—æ—¶
            all_update_times.extend(episode_result['update_duration'])
        
        # æ›´æ–°ç»Ÿè®¡æŒ‡æ ‡
        if episodes > 0:
            timing_stats['avg_episode_duration'] = total_episode_durations / episodes
        
        if all_step_times:
            avg_step_s = sum(all_step_times) / len(all_step_times)
            timing_stats['avg_step_duration_ms'] = avg_step_s * 1000
            timing_stats['max_step_duration_ms'] = max(all_step_times) * 1000
            timing_stats['min_step_duration_ms'] = min(all_step_times) * 1000
        
        if all_decision_times:
            avg_decision_s = sum(all_decision_times) / len(all_decision_times)
            timing_stats['avg_decision_duration_ms'] = avg_decision_s * 1000
            timing_stats['max_decision_duration_ms'] = max(all_decision_times) * 1000
            timing_stats['min_decision_duration_ms'] = min(all_decision_times) * 1000
        
        if all_update_times:
            total_update_s = sum(all_update_times)
            avg_update_s = total_update_s / len(all_update_times)
            timing_stats['total_update_duration_ms'] = total_update_s * 1000
            timing_stats['avg_update_duration_ms'] = avg_update_s * 1000
            timing_stats['update_count'] = len(all_update_times)
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå›åˆçš„æ•°æ®ä½œä¸ºåŸºç¡€ï¼Œæ·»åŠ æ€»ç»Ÿè®¡å’Œè€—æ—¶ç»Ÿè®¡ï¼‰
        final_results = all_episode_results[0].copy()
        final_results['all_episodes'] = all_episode_results
        final_results['total_reward'] = total_reward
        final_results['total_steps'] = total_steps
        final_results['avg_reward'] = overall_avg_reward
        final_results['episodes'] = episodes
        final_results['timing_stats'] = timing_stats
        
        print(f"\nâœ… åœºæ™¯ {scenario} æµ‹è¯•å®Œæˆ")
        print(f"   æ€»å¥–åŠ±: {total_reward:.2f}")
        print(f"   å¹³å‡å¥–åŠ±: {overall_avg_reward:.4f}")
        print(f"   æ€»æ­¥æ•°: {total_steps}")
        
        # æ‰“å°è€—æ—¶ç»Ÿè®¡
        print(f"\n   â±ï¸  è€—æ—¶ç»Ÿè®¡:")
        print(f"   å¹³å‡æ¯å›åˆè€—æ—¶: {timing_stats['avg_episode_duration']:.4f}ç§’")
        print(f"   å¹³å‡æ¯æ­¥è€—æ—¶: {timing_stats['avg_step_duration_ms']:.4f}æ¯«ç§’")
        print(f"   å¹³å‡å†³ç­–è€—æ—¶: {timing_stats['avg_decision_duration_ms']:.4f}æ¯«ç§’")
        print(f"   æœ€å°å†³ç­–è€—æ—¶: {timing_stats['min_decision_duration_ms']:.4f}æ¯«ç§’")
        print(f"   æœ€å¤§å†³ç­–è€—æ—¶: {timing_stats['max_decision_duration_ms']:.4f}æ¯«ç§’")
        print(f"   å¹³å‡æ›´æ–°è€—æ—¶: {timing_stats['avg_update_duration_ms']:.4f}æ¯«ç§’")
        print(f"   æ€»æ›´æ–°æ¬¡æ•°: {timing_stats['update_count']}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        if save_results:
            self._save_test_results(final_results)
        
        return final_results
    
    @classmethod
    def plot_power_profiles(cls, all_results, save_path, show_plot=False):
        """
        ç»˜åˆ¶3ç§åœºæ™¯çš„åŠŸç‡åˆ†é…ç»“æœï¼Œ3è¡Œ1åˆ—å­å›¾ï¼Œå‚è€ƒè¶…çº§ç¯å¢ƒplot_scenario_profilesçš„ç»˜åˆ¶æ–¹å¼
        
        Args:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
            save_path: å›¾åƒä¿å­˜è·¯å¾„
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ
        """
        # å»¶è¿Ÿå¯¼å…¥matplotlib
        matplotlib, plt = setup_matplotlib()
        
        # 3ç§åœºæ™¯çš„é¡ºåºå’Œé…ç½®
        scenarios = [
            ('cruise', 'Long-Endurance Cruise', '#1f77b4'),
            ('recon', 'Cross-Domain Reconnaissance', '#ff7f0e'),
            ('rescue', 'Emergency Rescue', '#2ca02c')
        ]
        
        # é¢œè‰²é…ç½®
        power_colors = {
            'load': '#f09639',  # åŠŸç‡éœ€æ±‚
            'fc': '#c84343',     # ç‡ƒæ–™ç”µæ± 
            'bat': '#42985e',    # ç”µæ± 
            'sc': '#8a7ab5'      # è¶…çº§ç”µå®¹
        }
        
        # åŸºç¡€åŠŸç‡å’Œæ¸©åº¦å‚è€ƒå€¼
        # å…¨å±€å­—ä½“å¤§å°è®¾ç½®
        GLOBAL_FONTSIZE = 16
        
        P_AIR_BASE = 2500
        P_SURFACE_BASE = 1000
        P_UNDERWATER_BASE = 3000
        T_AIR = 0
        T_SURFACE = 20
        T_UNDERWATER = 5
        
        # åˆ›å»º3è¡Œ1åˆ—å­å›¾ï¼Œå…±äº«Xè½´
        fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)
        
        # ç»˜åˆ¶æ¯ä¸ªåœºæ™¯
        for idx, (scenario_type, scenario_label, scenario_color) in enumerate(scenarios):
            ax1 = axes[idx]
            ax2 = ax1.twinx()  # å…±äº«Xè½´çš„æ¸©åº¦è½´
            
            # è·å–å½“å‰åœºæ™¯çš„ç»“æœ
            if scenario_type in all_results:
                scenario_result = all_results[scenario_type]
                
                # å‡†å¤‡æ•°æ®
                times = scenario_result['steps']
                load_demand = scenario_result['load_demand']
                power_fc = scenario_result['power_fc']
                power_bat = scenario_result['power_bat']
                power_sc = scenario_result['power_sc']
                temperature = scenario_result['temperature']
                soc_bat = scenario_result['soc_bat']
                soc_sc = scenario_result['soc_sc']
                
                # æ„å»ºæ¨¡æ€é˜¶æ®µä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œæ ¹æ®æ—¶é—´åŒºé—´åˆ’åˆ†ï¼‰
                modes = []
                if scenario_type == 'cruise':
                    # é•¿èˆªæ—¶å·¡èˆªï¼šç©ºä¸­(0-600)â†’åˆ‡æ¢(600-650)â†’æ°´é¢(650-1150)â†’åˆ‡æ¢(1150-1200)â†’ç©ºä¸­(1200-1800)
                    modes = [
                        {'type': 'air', 'start': 0, 'end': 600, 'label': 'Air Flight'},
                        {'type': 'air_to_surface_switch', 'start': 600, 'end': 650, 'label': 'Airâ†’Surface Switch'},
                        {'type': 'surface', 'start': 650, 'end': 1150, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1150, 'end': 1200, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1200, 'end': 1800, 'label': 'Air Flight'}
                    ]
                elif scenario_type == 'recon':
                    # è·¨åŸŸä¾¦å¯Ÿï¼šç©ºä¸­(0-200)â†’åˆ‡æ¢(200-250)â†’æ°´ä¸‹(250-1300)â†’åˆ‡æ¢(1300-1350)â†’æ°´é¢(1350-1550)â†’åˆ‡æ¢(1550-1600)â†’ç©ºä¸­(1600-1800)
                    modes = [
                        {'type': 'air', 'start': 0, 'end': 200, 'label': 'Air Flight'},
                        {'type': 'air_to_underwater_switch', 'start': 200, 'end': 250, 'label': 'Airâ†’Underwater Switch'},
                        {'type': 'underwater', 'start': 250, 'end': 1300, 'label': 'Underwater Navigation'},
                        {'type': 'underwater_to_surface_switch', 'start': 1300, 'end': 1350, 'label': 'Underwaterâ†’Surface Switch'},
                        {'type': 'surface', 'start': 1350, 'end': 1550, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1550, 'end': 1600, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1600, 'end': 1800, 'label': 'Air Flight'}
                    ]
                elif scenario_type == 'rescue':
                    # åº”æ€¥æ•‘æ´ï¼šæ°´é¢(0-320)â†’åˆ‡æ¢(320-370)â†’ç©ºä¸­(370-690)â†’åˆ‡æ¢(690-740)â†’æ°´ä¸‹(740-1060)â†’åˆ‡æ¢(1060-1110)â†’æ°´é¢(1110-1430)â†’åˆ‡æ¢(1430-1480)â†’ç©ºä¸­(1480-1800)
                    modes = [
                        {'type': 'surface', 'start': 0, 'end': 320, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 320, 'end': 370, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 370, 'end': 690, 'label': 'Air Flight'},
                        {'type': 'air_to_underwater_switch', 'start': 690, 'end': 740, 'label': 'Airâ†’Underwater Switch'},
                        {'type': 'underwater', 'start': 740, 'end': 1060, 'label': 'Underwater Navigation'},
                        {'type': 'underwater_to_surface_switch', 'start': 1060, 'end': 1110, 'label': 'Underwaterâ†’Surface Switch'},
                        {'type': 'surface', 'start': 1110, 'end': 1430, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1430, 'end': 1480, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1480, 'end': 1800, 'label': 'Air Flight'}
                    ]
                
                # ç»˜åˆ¶åŠŸç‡æ›²çº¿
                ax1.plot(times, load_demand, label='Power Demand', color=scenario_color, linewidth=1.2, linestyle='-')
                ax1.plot(times, power_fc, label='Fuel Cell', color=power_colors['fc'], linewidth=1.2, linestyle='-')
                ax1.plot(times, power_bat, label='Battery', color=power_colors['bat'], linewidth=1.2, linestyle='-')
                ax1.plot(times, power_sc, label='Super Capacitor', color=power_colors['sc'], linewidth=1.2, linestyle='-')
                
                # å¡«å……åŠŸç‡åŒºåŸŸï¼ˆä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼Œä½¿ç”¨åœºæ™¯é¢œè‰²ï¼‰
                ax1.fill_between(times, 0, load_demand, color=scenario_color, alpha=0.1)
                
                # æ·»åŠ åŸºç¡€åŠŸç‡å‚è€ƒçº¿ï¼ˆä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼‰
                ax1.axhline(y=P_AIR_BASE, color='#1f77b4', linestyle='--', linewidth=1.5, alpha=0.6, label=f'Air Base Power ({P_AIR_BASE}W)')
                ax1.axhline(y=P_SURFACE_BASE, color='#ff7f0e', linestyle='--', linewidth=1.5, alpha=0.6, label=f'Surface Base Power ({P_SURFACE_BASE}W)')
                ax1.axhline(y=P_UNDERWATER_BASE, color='#2ca02c', linestyle='--', linewidth=1.5, alpha=0.6, label=f'Underwater Base Power ({P_UNDERWATER_BASE}W)')
                
                # ç»˜åˆ¶æ¸©åº¦æ›²çº¿ï¼ˆä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼‰
                ax2.plot(times, temperature, color='darkred', linestyle='--', linewidth=1.2, label='Temperature')
                
                # ç»˜åˆ¶SOCæ›²çº¿ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
                ax2.plot(times, [soc * 100 for soc in soc_bat], color='purple', linestyle='-.', linewidth=1.2, label='Battery SOC')
                ax2.plot(times, [soc * 100 for soc in soc_sc], color='cyan', linestyle=':', linewidth=1.2, label='SuperCap SOC')
                
                # æ·»åŠ æ¸©åº¦å‚è€ƒçº¿
                ax2.axhline(y=T_AIR, color='blue', linestyle=':', linewidth=1.5, alpha=0.6, label=f'Air Temp ({T_AIR}â„ƒ)')
                ax2.axhline(y=T_SURFACE, color='orange', linestyle=':', linewidth=1.5, alpha=0.6, label=f'Surface Temp ({T_SURFACE}â„ƒ)')
                ax2.axhline(y=T_UNDERWATER, color='green', linestyle=':', linewidth=1.5, alpha=0.6, label=f'Underwater Temp ({T_UNDERWATER}â„ƒ)')
                
                # æ ‡æ³¨æ¨¡æ€é˜¶æ®µï¼ˆå…ˆç»˜åˆ¶èƒŒæ™¯è‰²ï¼Œå†æ·»åŠ æ ‡ç­¾ï¼Œç¡®ä¿åœ¨æœ€ä¸Šå±‚ï¼‰
                for mode in modes:
                    # ç»˜åˆ¶æ¨¡æ€èƒŒæ™¯è‰²
                    if 'air' in mode['type'] and 'switch' not in mode['type']:
                        ax1.axvspan(mode['start'], mode['end'], alpha=0.1, color='lightblue')
                    elif 'surface' in mode['type'] and 'switch' not in mode['type']:
                        ax1.axvspan(mode['start'], mode['end'], alpha=0.1, color='lightyellow')
                    elif 'underwater' in mode['type'] and 'switch' not in mode['type']:
                        ax1.axvspan(mode['start'], mode['end'], alpha=0.1, color='lightgreen')
                    elif 'switch' in mode['type']:
                        ax1.axvspan(mode['start'], mode['end'], alpha=0.2, color='orange')
                
                # æ·»åŠ æ¨¡æ€æ ‡ç­¾ï¼ˆä»…æ ‡æ³¨ä¸»è¦æ¨¡æ€ï¼Œä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼‰
                for mode in modes:
                    if 'switch' not in mode['type']:
                        mid_time = (mode['start'] + mode['end']) / 2
                        ax1.text(mid_time, ax1.get_ylim()[1]*0.7, mode['label'], 
                                ha='center', va='center', fontsize=9, fontweight='bold',
                                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
                
                # è®¾ç½®å­å›¾å±æ€§
                ax1.set_title(scenario_label, fontsize=14, fontweight='bold', pad=10)  # ä¸è¶…çº§ç¯å¢ƒä¸€è‡´
                ax1.set_ylabel('Power (W)', fontsize=GLOBAL_FONTSIZE, fontweight='bold')
                ax1.grid(True, linestyle='--', alpha=0.7)
                ax1.set_ylim(0, max(max(load_demand), max(power_fc), max(power_bat), max(power_sc)) * 1.1)
                ax1.tick_params(axis='y', labelsize=GLOBAL_FONTSIZE)
                
                ax2.set_ylabel('Temperature (â„ƒ) / SOC (%)', fontsize=GLOBAL_FONTSIZE, fontweight='bold', color='darkred')
                ax2.set_ylim(-5, 105)
                ax2.tick_params(axis='y', labelsize=GLOBAL_FONTSIZE, colors='darkred')
                
                # ç¾åŒ–è¾¹æ¡†
                ax1.spines['top'].set_visible(False)
                ax2.spines['top'].set_visible(False)
                
                # ä¿å­˜å›¾ä¾‹ä¿¡æ¯ï¼Œä½†ä¸åœ¨å•ä¸ªaxä¸Šç»˜åˆ¶
                if idx == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªå­å›¾æ”¶é›†å›¾ä¾‹ä¿¡æ¯
                    lines1, labels1 = ax1.get_legend_handles_labels()
                    lines2, labels2 = ax2.get_legend_handles_labels()
                    fig_legend_handles = lines1 + lines2
                    fig_legend_labels = labels1 + labels2
            else:
                ax1.set_ylabel('Power (W)', fontsize=GLOBAL_FONTSIZE, fontweight='bold')
                ax1.grid(True, linestyle='--', alpha=0.7)
                ax1.spines['top'].set_visible(False)
                ax2.spines['top'].set_visible(False)
        
        # è®¾ç½®Xè½´
        axes[-1].set_xlabel('Time (s)', fontsize=GLOBAL_FONTSIZE, fontweight='bold')
        axes[-1].set_xlim(0, 1800)  # è®¾ç½®ä¸º1800s
        axes[-1].set_xticks(np.arange(0, 1801, 200))  # æ¯200sä¸€ä¸ªåˆ»åº¦
        axes[-1].tick_params(axis='x', labelsize=GLOBAL_FONTSIZE)
        
        # åˆ›å»ºfigureçº§åˆ«çš„å…±äº«å›¾ä¾‹ï¼ˆä½äºæ‰€æœ‰Axesä¹‹ä¸Šï¼Œä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼‰
        if 'fig_legend_handles' in locals() and 'fig_legend_labels' in locals():
            fig.legend(fig_legend_handles, fig_legend_labels, loc='upper center', fontsize=9, framealpha=0.9, 
                      bbox_to_anchor=(0.5, 0.92), ncol=6)  # é¡¶éƒ¨å±…ä¸­ï¼Œ6åˆ—å¸ƒå±€ï¼Œä¸è¶…çº§ç¯å¢ƒä¸€è‡´
        
        # è°ƒæ•´å¸ƒå±€ï¼ˆä¸è¶…çº§ç¯å¢ƒä¸€è‡´ï¼‰
        plt.tight_layout(rect=[0, 0, 1, 0.88])  # è°ƒæ•´é¡¶éƒ¨è¾¹è·ä»¥å®¹çº³å›¾ä¾‹
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(save_path, dpi=1200, bbox_inches='tight')
        print(f"âœ… åŠŸç‡åˆ†é…ç»“æœå›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        # æ˜¾ç¤ºå›¾åƒï¼ˆå¯é€‰ï¼‰
        if show_plot:
            plt.show()
        else:
            plt.close()
    
    def test_all_scenarios(self, max_steps=1000, save_results=True, show_plot=False, episodes=1):
        """
        æµ‹è¯•æŒ‡å®šçš„ä¸‰ä¸ªç¯å¢ƒ
        
        Args:
            max_steps: æœ€å¤§æµ‹è¯•æ­¥æ•°
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ
            episodes: æµ‹è¯•å›åˆæ•°
        
        Returns:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
        """
        # åªæµ‹è¯•æŒ‡å®šçš„ä¸‰ä¸ªç¯å¢ƒ
        scenarios = ['cruise', 'recon', 'rescue']
        
        # æµ‹è¯•æ‰€æœ‰åœºæ™¯
        all_results = {}
        for scenario in scenarios:
            results = self.test_single_scenario(scenario, max_steps, save_results, episodes)
            all_results[scenario] = results
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        if save_results:
            self._save_summary_results(all_results)
            
            # ç»˜åˆ¶åŠŸç‡åˆ†é…å›¾åƒ
            results_dir = os.path.join(
                os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
                self.timestamp
            )
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(results_dir, exist_ok=True)
            plot_path = os.path.join(results_dir, "power_distribution_3_scenarios.svg")
            self.plot_power_profiles(all_results, plot_path, show_plot)
        
        return all_results
    
    def _save_test_results(self, results):
        """
        ä¿å­˜æµ‹è¯•ç»“æœ
        
        Args:
            results: æµ‹è¯•ç»“æœ
        """
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„timestampï¼‰
        results_dir = os.path.join(
            os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
            self.timestamp
        )
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜å•ä¸ªåœºæ™¯ç»“æœ
        scenario = results['scenario']
        result_path = os.path.join(results_dir, f"fast_adaptation_result_{scenario}.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, cls=NumpyEncoder, indent=4)
        
        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_path}")
    
    def _save_summary_results(self, all_results):
        """
        ä¿å­˜æ±‡æ€»æµ‹è¯•ç»“æœ
        
        Args:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
        """
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„timestampï¼‰
        results_dir = os.path.join(
            os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
            self.timestamp
        )
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_path = os.path.join(results_dir, "fast_adaptation_summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, cls=NumpyEncoder, indent=4)
        
        # ä¿å­˜è¶…å‚æ•°
        hyperparams_path = os.path.join(results_dir, "fast_adaptation_hyperparams.json")
        with open(hyperparams_path, 'w', encoding='utf-8') as f:
            json.dump(self.hyperparams, f, cls=NumpyEncoder, indent=4)
        
        print(f"ğŸ“Š æ±‡æ€»ç»“æœå·²ä¿å­˜åˆ°: {summary_path}")
        print(f"ğŸ“‹ è¶…å‚æ•°å·²ä¿å­˜åˆ°: {hyperparams_path}")
    
    def save_model(self, save_path):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
        """
        torch.save(self.model.state_dict(), save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='å¿«å­¦ä¹ /å¿«æµ‹è¯•è„šæœ¬')
    
    # æ ¸å¿ƒå‚æ•°
    parser.add_argument('--model-path', type=str, required=False,
                        help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆ--plot-onlyæ¨¡å¼ä¸‹å¯é€‰ï¼‰')
    parser.add_argument('--hyperparams-path', type=str, default=None,
                        help='å¿«å­¦ä¹ è¶…å‚æ•°è·¯å¾„')
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument('--scenario', type=str, default=None,
                        help='æµ‹è¯•åœºæ™¯åç§°ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰åœºæ™¯ï¼‰')
    parser.add_argument('--episodes', type=int, default=1,
                        help='æµ‹è¯•å›åˆæ•°ï¼ˆé»˜è®¤ï¼š1ï¼‰')
    parser.add_argument('--max-steps', type=int, default=1800,
                        help='æ¯ä¸ªåœºæ™¯çš„æœ€å¤§æµ‹è¯•æ­¥æ•°')
    parser.add_argument('--save-results', action='store_true',
                        help='æ˜¯å¦ä¿å­˜æµ‹è¯•ç»“æœ')
    parser.add_argument('--show-plot', action='store_true',
                        help='æ˜¯å¦æ˜¾ç¤ºæµ‹è¯•ç»“æœå›¾ï¼ˆé»˜è®¤ï¼šä»…ä¿å­˜ä¸æ˜¾ç¤ºï¼‰')
    
    # å¿«é€Ÿç»˜å›¾å‚æ•°
    parser.add_argument('--plot-only', type=str, default=None,
                        help='è·¯å¾„åˆ°ä¹‹å‰ä¿å­˜çš„ç»“æœï¼Œè·³è¿‡æµ‹è¯•ç›´æ¥ç»˜å›¾')
    
    # è‡ªå®šä¹‰è¶…å‚æ•°
    parser.add_argument('--lr', type=float, default=None,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--kl-threshold', type=float, default=None,
                        help='KLæ•£åº¦é˜ˆå€¼')
    parser.add_argument('--window-size', type=int, default=None,
                        help='æ»‘åŠ¨çª—å£å¤§å°')
    
    return parser.parse_args()

def main():
    """
    ä¸»å‡½æ•°
    """
    args = parse_args()
    
    # --plot-onlyæ¨¡å¼ï¼šç›´æ¥ä»ä¿å­˜çš„ç»“æœç»˜å›¾
    if args.plot_only:
        print(f"ğŸ“Š è¿›å…¥--plot-onlyæ¨¡å¼ï¼Œä»{args.plot_only}åŠ è½½ç»“æœ")
        
        # åŠ è½½ä¿å­˜çš„ç»“æœ
        if os.path.exists(args.plot_only):
            with open(args.plot_only, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            # ç¡®å®šç»˜å›¾è·¯å¾„
            plot_path = os.path.join(os.path.dirname(args.plot_only), "power_distribution_fast.svg")
            
            # åˆ›å»ºä¸€ä¸ªæœ€å°åŒ–çš„trainerå®ä¾‹ï¼Œä»…ç”¨äºè°ƒç”¨plot_power_profiles
            if args.model_path:
                trainer = FastAdaptationTrainer(
                    model_path=args.model_path,
                    hyperparams_path=args.hyperparams_path,
                    custom_hyperparams={}
                )
            else:
                # å¦‚æœæ²¡æœ‰æä¾›æ¨¡å‹è·¯å¾„ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨é™æ€æ–¹æ³•
                trainer = type('DummyTrainer', (), {
                    'timestamp': datetime.now().strftime("%m%d_%H%M%S"),
                    'plot_power_profiles': FastAdaptationTrainer.plot_power_profiles
                })()
            
            # è°ƒç”¨ç»˜å›¾å‡½æ•°
            trainer.plot_power_profiles(results, plot_path, show_plot=args.show_plot)
            print(f"\n=== å¿«é€Ÿç»˜å›¾å®Œæˆ ===")
            return
        else:
            print(f"âŒ é”™è¯¯ï¼šç»“æœæ–‡ä»¶{args.plot_only}ä¸å­˜åœ¨")
            sys.exit(1)
    
    # æ­£å¸¸æµ‹è¯•æ¨¡å¼
    if not args.model_path:
        print(f"âŒ é”™è¯¯ï¼šæ­£å¸¸æµ‹è¯•æ¨¡å¼ä¸‹å¿…é¡»æä¾›--model-pathå‚æ•°")
        sys.exit(1)
    
    # æ„å»ºè‡ªå®šä¹‰è¶…å‚æ•°
    custom_hyperparams = {}
    if args.lr:
        custom_hyperparams['lr'] = args.lr
    if args.kl_threshold:
        custom_hyperparams['kl_threshold'] = args.kl_threshold
    if args.window_size:
        custom_hyperparams['window_size'] = args.window_size
    
    # åˆå§‹åŒ–å¿«å­¦ä¹ è®­ç»ƒå™¨
    trainer = FastAdaptationTrainer(
        model_path=args.model_path,
        hyperparams_path=args.hyperparams_path,
        custom_hyperparams=custom_hyperparams
    )
    
    # æµ‹è¯•åœºæ™¯
    if args.scenario:
        if args.scenario == "classical":
            # æµ‹è¯•ç»å…¸åœºæ™¯ï¼ˆcruise, recon, rescueï¼‰
            trainer.test_all_scenarios(
                max_steps=args.max_steps,
                save_results=args.save_results,
                show_plot=args.show_plot,
                episodes=args.episodes
            )
        else:
            # æµ‹è¯•å•ä¸ªåœºæ™¯
            results = trainer.test_single_scenario(
                scenario=args.scenario,
                max_steps=args.max_steps,
                save_results=args.save_results,
                episodes=args.episodes
            )
            
            # å¦‚æœä¿å­˜ç»“æœï¼Œç»˜åˆ¶å•ä¸ªåœºæ™¯çš„åŠŸç‡åˆ†é…å›¾åƒ
            if args.save_results:
                # ç»˜åˆ¶å•ä¸ªåœºæ™¯çš„åŠŸç‡åˆ†é…å›¾åƒ
                results_dir = os.path.join(
                    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
                    trainer.timestamp
                )
                plot_path = os.path.join(results_dir, f"power_distribution_{args.scenario}.svg")
                
                # åˆ›å»ºå•ä¸ªåœºæ™¯çš„ç»“æœå­—å…¸
                single_result = {args.scenario: results}
                
                # è°ƒç”¨ç»˜å›¾å‡½æ•°
                trainer.plot_power_profiles(single_result, plot_path, show_plot=args.show_plot)
    else:
        # æµ‹è¯•æ‰€æœ‰åœºæ™¯
        trainer.test_all_scenarios(
            max_steps=args.max_steps,
            save_results=args.save_results,
            show_plot=args.show_plot,
            episodes=args.episodes
        )
    
    print(f"\n=== å¿«å­¦ä¹ /å¿«æµ‹è¯•å®Œæˆ ===")

if __name__ == '__main__':
    main()

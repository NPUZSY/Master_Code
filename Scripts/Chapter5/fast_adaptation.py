#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«å­¦ä¹ /å¿«æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½æ…¢å­¦ä¹ è®­ç»ƒçš„æƒé‡å‚æ•°å’Œå­¦ä¹ è¶…å‚æ•°
2. å®ç°ç¯å¢ƒåˆ†å¸ƒå·®å¼‚åº¦é‡ï¼ˆKLæ•£åº¦ï¼‰
3. å®ç°æ›´æ–°è§¦å‘æ¡ä»¶
4. å®ç°åœ¨çº¿æ›´æ–°æµç¨‹
5. æ”¯æŒåœ¨ä¸åŒç¯å¢ƒä¸‹è¿›è¡Œå¿«æµ‹è¯•
6. æ”¯æŒä¸€é”®æµ‹è¯•è¶…çº§ç¯å¢ƒä¸‹çš„æ‰€æœ‰ç¯å¢ƒ
7. æ”¯æŒè‡ªä¸»æŒ‡å®šåœ¨çº¿å­¦ä¹ è¶…å‚æ•°

å‚è€ƒæ–‡ç« ä¸­çš„å­¦ä¹ æµç¨‹ï¼š
- ç¯å¢ƒåˆ†å¸ƒå·®å¼‚åº¦é‡ï¼šKLæ•£åº¦
- æ»‘åŠ¨çª—å£é‡‡æ ·-æ ¸å¯†åº¦ä¼°è®¡
- åŒé‡è§¦å‘æœºåˆ¶ï¼šKLæ•£åº¦é˜ˆå€¼ + æ€§èƒ½æŒ‡æ ‡é˜ˆå€¼
- åœ¨çº¿æ›´æ–°æµç¨‹ï¼šå‚æ•°å¤‡ä»½ â†’ å±€éƒ¨å‚æ•°ä¼˜åŒ– â†’ æ›´æ–°æ•ˆæœéªŒè¯
"""

import os
import sys
import time
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.neighbors import KernelDensity
import json
from datetime import datetime

# å»¶è¿Ÿå¯¼å…¥matplotlibï¼Œä»…åœ¨éœ€è¦æ—¶å¯¼å…¥
def setup_matplotlib():
    """
    è®¾ç½®matplotlibç¯å¢ƒ
    """
    # å¯¼å…¥matplotlib
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
    import matplotlib.pyplot as plt
    return matplotlib, plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
from Scripts.Chapter5.Meta_RL_Engine import MetaRLPolicy
from Scripts.Chapter3.MARL_Engine import device
from Scripts.Chapter5.Env_Ultra import EnvUltra

class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyç±»å‹"""
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        return super(NumpyEncoder, self).default(obj)

class FastAdaptationTrainer:
    """
    å¿«å­¦ä¹ /å¿«æµ‹è¯•è®­ç»ƒå™¨
    """
    def __init__(self, model_path, hyperparams_path=None, custom_hyperparams=None):
        """
        åˆå§‹åŒ–å¿«å­¦ä¹ è®­ç»ƒå™¨
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            hyperparams_path: å¿«å­¦ä¹ è¶…å‚æ•°è·¯å¾„
            custom_hyperparams: è‡ªå®šä¹‰è¶…å‚æ•°
        """
        # ç”Ÿæˆå”¯ä¸€çš„timestampï¼Œç”¨äºæ‰€æœ‰ç»“æœä¿å­˜
        self.timestamp = datetime.now().strftime("%m%d_%H%M%S")
        
        # åŠ è½½æ¨¡å‹
        self.hidden_dim = self._infer_hidden_dim(model_path)
        self.model = MetaRLPolicy(hidden_dim=self.hidden_dim).to(device)
        self.model.load_state_dict(torch.load(model_path, map_location=device))
        self.model.eval()
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
        
        # åŠ è½½è¶…å‚æ•°
        self.hyperparams = self._load_hyperparams(hyperparams_path, custom_hyperparams)
        print(f"âœ… æˆåŠŸåŠ è½½è¶…å‚æ•°")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.hyperparams['lr'])
        self.loss_func = nn.SmoothL1Loss()
        
        # åˆå§‹åŒ–æ»‘åŠ¨çª—å£
        self.window_size = self.hyperparams['window_size']
        self.temp_window = []  # æ¸©åº¦æ»‘åŠ¨çª—å£
        self.power_window = []  # åŠŸç‡éœ€æ±‚æ»‘åŠ¨çª—å£
        
        # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            'power_matching': [],
            'hydrogen_growth': [],
            'soc_fluctuation': []
        }
        
        # åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒåˆ†å¸ƒï¼ˆä»è®­ç»ƒæ•°æ®ä¸­ä¼°è®¡ï¼‰
        self.train_temp_dist = None
        self.train_power_dist = None
        self._estimate_train_distributions()
        
        # åˆå§‹åŒ–å‚æ•°å¤‡ä»½
        self.params_backup = None
        
    def _infer_hidden_dim(self, model_path):
        """
        ä»æ¨¡å‹æ–‡ä»¶ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            hidden_dim: éšè—å±‚ç»´åº¦
        """
        # åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
        state_dict = torch.load(model_path, map_location=device)
        
        # ä»RNNå±‚å‚æ•°ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        for key in state_dict.keys():
            if 'rnn.weight_hh_l0' in key:
                # RNNéšè—å±‚ç»´åº¦æ˜¯weight_hh_l0çš„å½¢çŠ¶[out_features, hidden_size]çš„ç¬¬äºŒä¸ªç»´åº¦
                return state_dict[key].shape[1]
        
        # ä»fc_feature1å±‚å‚æ•°ä¸­æ¨æ–­éšè—å±‚ç»´åº¦
        for key in state_dict.keys():
            if 'fc_feature1.weight' in key:
                return state_dict[key].shape[1]
        
        return 512  # é»˜è®¤å€¼
    
    def _load_hyperparams(self, hyperparams_path, custom_hyperparams):
        """
        åŠ è½½è¶…å‚æ•°
        
        Args:
            hyperparams_path: è¶…å‚æ•°æ–‡ä»¶è·¯å¾„
            custom_hyperparams: è‡ªå®šä¹‰è¶…å‚æ•°
        
        Returns:
            åˆå¹¶åçš„è¶…å‚æ•°å­—å…¸
        """
        # é»˜è®¤è¶…å‚æ•°
        default_hyperparams = {
            "lr": 5e-5,
            "gamma": 0.95,
            "hidden_dim": 512,
            "batch_size": 32,
            "update_steps": 10,
            "kl_threshold": 0.3,
            "window_size": 100,
            "kl_weight_temp": 0.5,
            "kl_weight_power": 0.5,
            "power_matching_threshold": 0.9,
            "hydrogen_growth_threshold": 0.1,
            "soc_fluctuation_threshold": 0.08,
            "performance_check_steps": 50,
            "backup_params": True,
            "optimize_all_params": True,
            "validation_steps": 100,
            "success_reward_iterations": 10,
            "kernel_bandwidth_temp": 2.0,
            "kernel_bandwidth_power": 50.0,
            "density_estimation_method": "gaussian",
            "meta_lr": 5e-6,
            "meta_steps": 5,
            "adaptation_steps": 200,
            "performance_recovery_rate": 0.98
        }
        
        # ä»æ–‡ä»¶åŠ è½½è¶…å‚æ•°
        file_hyperparams = {}
        if hyperparams_path and os.path.exists(hyperparams_path):
            with open(hyperparams_path, 'r', encoding='utf-8') as f:
                file_hyperparams = json.load(f)
        
        # åˆå¹¶è¶…å‚æ•°ï¼šé»˜è®¤ â†’ æ–‡ä»¶ â†’ è‡ªå®šä¹‰
        hyperparams = default_hyperparams.copy()
        hyperparams.update(file_hyperparams)
        if custom_hyperparams:
            hyperparams.update(custom_hyperparams)
        
        return hyperparams
    
    def _estimate_train_distributions(self):
        """
        ä¼°è®¡è®­ç»ƒç¯å¢ƒçš„åˆ†å¸ƒ
        """
        # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºè®­ç»ƒç¯å¢ƒåˆ†å¸ƒ
        # å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä»80ç»„è®­ç»ƒåœºæ™¯æ•°æ®ä¸­ä¼°è®¡
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        np.random.seed(42)
        train_temp_data = np.random.normal(25, 5, size=10000)
        train_power_data = np.random.normal(2000, 500, size=10000)
        
        # ä½¿ç”¨æ ¸å¯†åº¦ä¼°è®¡è®­ç»ƒç¯å¢ƒåˆ†å¸ƒ
        self.train_temp_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_temp']
        )
        self.train_temp_dist.fit(train_temp_data.reshape(-1, 1))
        
        self.train_power_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_power']
        )
        self.train_power_dist.fit(train_power_data.reshape(-1, 1))
        
        print(f"âœ… æˆåŠŸä¼°è®¡è®­ç»ƒç¯å¢ƒåˆ†å¸ƒ")
    
    def _update_sliding_window(self, temp, power):
        """
        æ›´æ–°æ»‘åŠ¨çª—å£
        
        Args:
            temp: å½“å‰æ¸©åº¦
            power: å½“å‰åŠŸç‡éœ€æ±‚
        """
        # æ›´æ–°æ¸©åº¦æ»‘åŠ¨çª—å£
        self.temp_window.append(temp)
        if len(self.temp_window) > self.window_size:
            self.temp_window.pop(0)
        
        # æ›´æ–°åŠŸç‡éœ€æ±‚æ»‘åŠ¨çª—å£
        self.power_window.append(power)
        if len(self.power_window) > self.window_size:
            self.power_window.pop(0)
    
    def _estimate_current_distributions(self):
        """
        ä¼°è®¡å½“å‰ç¯å¢ƒçš„åˆ†å¸ƒ
        
        Returns:
            temp_dist: å½“å‰æ¸©åº¦åˆ†å¸ƒ
            power_dist: å½“å‰åŠŸç‡éœ€æ±‚åˆ†å¸ƒ
        """
        if len(self.temp_window) < self.window_size or len(self.power_window) < self.window_size:
            return None, None
        
        # ä¼°è®¡å½“å‰æ¸©åº¦åˆ†å¸ƒ
        temp_data = np.array(self.temp_window).reshape(-1, 1)
        temp_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_temp']
        )
        temp_dist.fit(temp_data)
        
        # ä¼°è®¡å½“å‰åŠŸç‡éœ€æ±‚åˆ†å¸ƒ
        power_data = np.array(self.power_window).reshape(-1, 1)
        power_dist = KernelDensity(
            kernel='gaussian', 
            bandwidth=self.hyperparams['kernel_bandwidth_power']
        )
        power_dist.fit(power_data)
        
        return temp_dist, power_dist
    
    def _calculate_kl_divergence(self, p_dist, q_dist, data):
        """
        è®¡ç®—KLæ•£åº¦ D_KL(P||Q)
        
        Args:
            p_dist: å½“å‰åˆ†å¸ƒ
            q_dist: è®­ç»ƒåˆ†å¸ƒ
            data: é‡‡æ ·æ•°æ®
        
        Returns:
            kl_divergence: KLæ•£åº¦å€¼
        """
        if p_dist is None or q_dist is None:
            return 0.0
        
        # è®¡ç®—log P(x) - log Q(x)
        log_p = p_dist.score_samples(data)
        log_q = q_dist.score_samples(data)
        
        # è®¡ç®—KLæ•£åº¦
        kl_divergence = np.mean(log_p - log_q)
        
        return max(0.0, kl_divergence)  # KLæ•£åº¦éè´Ÿ
    
    def _calculate_total_kl(self):
        """
        è®¡ç®—ç»¼åˆKLæ•£åº¦
        
        Returns:
            total_kl: ç»¼åˆKLæ•£åº¦å€¼
        """
        # ä¼°è®¡å½“å‰åˆ†å¸ƒ
        temp_dist, power_dist = self._estimate_current_distributions()
        if temp_dist is None or power_dist is None:
            return 0.0
        
        # å‡†å¤‡æ•°æ®
        temp_data = np.array(self.temp_window).reshape(-1, 1)
        power_data = np.array(self.power_window).reshape(-1, 1)
        
        # è®¡ç®—æ¸©åº¦KLæ•£åº¦
        kl_temp = self._calculate_kl_divergence(temp_dist, self.train_temp_dist, temp_data)
        
        # è®¡ç®—åŠŸç‡éœ€æ±‚KLæ•£åº¦
        kl_power = self._calculate_kl_divergence(power_dist, self.train_power_dist, power_data)
        
        # è®¡ç®—ç»¼åˆKLæ•£åº¦
        total_kl = (self.hyperparams['kl_weight_temp'] * kl_temp + 
                   self.hyperparams['kl_weight_power'] * kl_power)
        
        return total_kl
    
    def _update_performance_metrics(self, power_matching, hydrogen_growth, soc_fluctuation):
        """
        æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        
        Args:
            power_matching: åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
            hydrogen_growth: ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
            soc_fluctuation: é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        """
        # æ›´æ–°åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
        self.performance_metrics['power_matching'].append(power_matching)
        if len(self.performance_metrics['power_matching']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['power_matching'].pop(0)
        
        # æ›´æ–°ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
        self.performance_metrics['hydrogen_growth'].append(hydrogen_growth)
        if len(self.performance_metrics['hydrogen_growth']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['hydrogen_growth'].pop(0)
        
        # æ›´æ–°é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        self.performance_metrics['soc_fluctuation'].append(soc_fluctuation)
        if len(self.performance_metrics['soc_fluctuation']) > self.hyperparams['performance_check_steps']:
            self.performance_metrics['soc_fluctuation'].pop(0)
    
    def _check_performance_thresholds(self):
        """
        æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        
        Returns:
            performance_anomaly: æ˜¯å¦å­˜åœ¨æ€§èƒ½å¼‚å¸¸
        """
        # æ£€æŸ¥åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
        if self.performance_metrics['power_matching']:
            avg_power_matching = np.mean(self.performance_metrics['power_matching'])
            if avg_power_matching <= self.hyperparams['power_matching_threshold']:
                return True
        
        # æ£€æŸ¥ç­‰æ•ˆæ°¢è€—å¢é•¿ç‡
        if self.performance_metrics['hydrogen_growth']:
            avg_hydrogen_growth = np.mean(self.performance_metrics['hydrogen_growth'])
            if avg_hydrogen_growth >= self.hyperparams['hydrogen_growth_threshold']:
                return True
        
        # æ£€æŸ¥é”‚ç”µæ± SOCæ³¢åŠ¨å¹…åº¦
        if self.performance_metrics['soc_fluctuation']:
            avg_soc_fluctuation = np.mean(self.performance_metrics['soc_fluctuation'])
            if avg_soc_fluctuation >= self.hyperparams['soc_fluctuation_threshold']:
                return True
        
        return False
    
    def _should_update(self):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ›´æ–°
        
        Returns:
            should_update: æ˜¯å¦åº”è¯¥æ›´æ–°
        """
        # è®¡ç®—ç»¼åˆKLæ•£åº¦
        total_kl = self._calculate_total_kl()
        
        # æ£€æŸ¥KLæ•£åº¦é˜ˆå€¼
        if total_kl < self.hyperparams['kl_threshold']:
            return False
        
        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        performance_anomaly = self._check_performance_thresholds()
        
        return performance_anomaly
    
    def _backup_params(self):
        """
        å¤‡ä»½å½“å‰å‚æ•°
        """
        if self.hyperparams['backup_params']:
            self.params_backup = self.model.state_dict().copy()
            print(f"ğŸ“¦ å‚æ•°å¤‡ä»½å®Œæˆ")
    
    def _restore_params(self):
        """
        æ¢å¤å¤‡ä»½å‚æ•°
        """
        if self.params_backup is not None:
            self.model.load_state_dict(self.params_backup)
            print(f"ğŸ”„ å‚æ•°æ¢å¤å®Œæˆ")
    
    def _optimize_model(self, experiences):
        """
        ä¼˜åŒ–æ¨¡å‹å‚æ•°
        
        Args:
            experiences: ç»éªŒæ•°æ®
        """
        if not experiences:
            return
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # ä¼˜åŒ–æ¨¡å‹
        for _ in range(self.hyperparams['update_steps']):
            for exp in experiences:
                state = exp['state']
                reward = exp['reward']
                
                # æ„å»ºè®¡ç®—å›¾
                state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
                fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
                
                # è®¡ç®—æŸå¤±
                target = torch.tensor(reward, dtype=torch.float32).to(device)
                loss_fc = self.loss_func(fc_action_out, target.expand_as(fc_action_out)) * 1.5
                loss_bat = self.loss_func(bat_action_out, target.expand_as(bat_action_out))
                loss_sc = self.loss_func(sc_action_out, target.expand_as(sc_action_out))
                
                total_loss = loss_fc + loss_bat + loss_sc
                
                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                total_loss.backward()
                self.optimizer.step()
        
        # æ¢å¤æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.eval()
        
        print(f"âš¡ æ¨¡å‹ä¼˜åŒ–å®Œæˆï¼Œæ›´æ–°æ­¥æ•°: {self.hyperparams['update_steps']}")
    
    def _validate_update(self, env, max_steps=100):
        """
        éªŒè¯æ›´æ–°æ•ˆæœ
        
        Args:
            env: éªŒè¯ç¯å¢ƒ
            max_steps: éªŒè¯æ­¥æ•°
        
        Returns:
            update_success: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        state = env.reset()
        total_reward = 0.0
        success_count = 0
        
        for step in range(max_steps):
            # é€‰æ‹©åŠ¨ä½œ
            state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
            fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
            
            # è´ªå©ªé€‰æ‹©åŠ¨ä½œ
            fc_action = torch.argmax(fc_action_out, dim=1).item()
            bat_action = torch.argmax(bat_action_out, dim=1).item()
            sc_action = torch.argmax(sc_action_out, dim=1).item()
            
            action_list = [fc_action, bat_action, sc_action]
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, done, info = env.step(action_list)
            
            total_reward += reward
            state = next_state
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if reward > -100.0:  # å‡è®¾å¥–åŠ±å¤§äº-100ä¸ºæˆåŠŸ
                success_count += 1
            
            if done:
                break
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æˆåŠŸæ¡ä»¶
        success_rate = success_count / max_steps
        update_success = success_rate >= self.hyperparams['performance_recovery_rate']
        
        print(f"âœ… æ›´æ–°éªŒè¯å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.2f}")
        
        return update_success
    
    def test_single_scenario(self, scenario, max_steps=1000, save_results=True, episodes=1):
        """
        æµ‹è¯•å•ä¸ªåœºæ™¯
        
        Args:
            scenario: åœºæ™¯åç§°
            max_steps: æœ€å¤§æµ‹è¯•æ­¥æ•°
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            episodes: æµ‹è¯•å›åˆæ•°
        
        Returns:
            test_results: æµ‹è¯•ç»“æœ
        """
        print(f"\n=== æµ‹è¯•åœºæ™¯: {scenario}, å›åˆæ•°: {episodes} ===")
        
        # åˆå§‹åŒ–æ€»å¥–åŠ±å’Œæ€»æ­¥æ•°
        total_reward = 0.0
        total_steps = 0
        
        # ä¿å­˜æ¯ä¸ªå›åˆçš„ç»“æœ
        all_episode_results = []
        
        for episode in range(episodes):
            print(f"\n--- å›åˆ {episode+1}/{episodes} ---")
            
            # åˆ›å»ºç¯å¢ƒ
            env = EnvUltra(scenario_type=scenario)
            state = env.reset()
            
            # åˆå§‹åŒ–æ•°æ®æ”¶é›†
            episode_results = {
                'scenario': scenario,
                'episode': episode+1,
                'steps': [],
                'rewards': [],
                'power_fc': [],
                'power_bat': [],
                'power_sc': [],
                'load_demand': [],
                'temperature': [],
                'soc_bat': [],
                'soc_sc': [],
                'kl_values': [],
            'updates_triggered': 0
        }
        
            # åˆå§‹åŒ–å›åˆç›¸å…³å˜é‡
            episode_total_reward = 0.0
            episode_update_triggered = False
            episode_experiences = []
            episode_update_count = 0
            
            # é‡ç½®æ»‘åŠ¨çª—å£å’Œæ€§èƒ½æŒ‡æ ‡
            self._reset_sliding_window()
            self._reset_performance_metrics()
            
            # å›åˆæµ‹è¯•å¾ªç¯
            for step in range(max_steps):
                # é€‰æ‹©åŠ¨ä½œ
                state_tensor = torch.FloatTensor(state).unsqueeze(0).unsqueeze(1).to(device)
                fc_action_out, bat_action_out, sc_action_out, _ = self.model(state_tensor, None)
                
                # è´ªå©ªé€‰æ‹©åŠ¨ä½œ
                fc_action = torch.argmax(fc_action_out, dim=1).item()
                bat_action = torch.argmax(bat_action_out, dim=1).item()
                sc_action = torch.argmax(sc_action_out, dim=1).item()
                
                action_list = [fc_action, bat_action, sc_action]
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, info = env.step(action_list)
                
                # æ›´æ–°æ»‘åŠ¨çª—å£
                temp = info['T_amb']
                power_demand = info['P_load']
                self._update_sliding_window(temp, power_demand)
                
                # è®¡ç®—åŠŸç‡ä¾›éœ€åŒ¹é…åº¦
                total_supply = info['P_fc'] + info['P_bat'] + info['P_sc']
                power_matching = min(1.0, total_supply / power_demand) if power_demand > 0 else 1.0
                
                # è®¡ç®—SOCæ³¢åŠ¨å¹…åº¦ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                soc_fluctuation = abs(next_state[5] - state[5])
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                self._update_performance_metrics(power_matching, 0.0, soc_fluctuation)  # ç®€åŒ–è®¡ç®—
                
                # è®¡ç®—ç»¼åˆKLæ•£åº¦
                total_kl = self._calculate_total_kl()
                
                # æ”¶é›†ç»éªŒæ•°æ®
                episode_experiences.append({
                    'state': state,
                    'reward': reward
                })
                
                # é™åˆ¶ç»éªŒæ•°æ®é•¿åº¦
                if len(episode_experiences) > self.hyperparams['batch_size']:
                    episode_experiences.pop(0)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ›´æ–°
                if self._should_update() and not episode_update_triggered:
                    print(f"ğŸš€ è§¦å‘æ›´æ–°ï¼ŒKLæ•£åº¦: {total_kl:.4f}, æ­¥æ•°: {step}")
                    
                    # å¤‡ä»½å‚æ•°
                    self._backup_params()
                    
                    # ä¼˜åŒ–æ¨¡å‹
                    self._optimize_model(episode_experiences)
                    
                    # éªŒè¯æ›´æ–°æ•ˆæœ
                    if not self._validate_update(env, self.hyperparams['validation_steps']):
                        # æ¢å¤å¤‡ä»½å‚æ•°
                        self._restore_params()
                    else:
                        episode_update_count += 1
                    
                    episode_update_triggered = True
                
                # æ”¶é›†æµ‹è¯•æ•°æ®
                episode_results['steps'].append(step)
                episode_results['rewards'].append(reward)
                episode_results['power_fc'].append(info['P_fc'])
                episode_results['power_bat'].append(info['P_bat'])
                episode_results['power_sc'].append(info['P_sc'])
                episode_results['load_demand'].append(power_demand)
                episode_results['temperature'].append(temp)
                episode_results['soc_bat'].append(next_state[5])
                episode_results['soc_sc'].append(next_state[6])
                episode_results['kl_values'].append(total_kl)
                
                episode_total_reward += reward
                state = next_state
                
                if done:
                    break
            
            # è®¡ç®—å›åˆç»Ÿè®¡æŒ‡æ ‡
            episode_avg_reward = episode_total_reward / (step + 1) if step > 0 else 0.0
            episode_results['avg_reward'] = episode_avg_reward
            episode_results['total_reward'] = episode_total_reward
            episode_results['total_steps'] = step + 1
            episode_results['updates_triggered'] = episode_update_count
            
            # æ·»åŠ åˆ°æ‰€æœ‰å›åˆç»“æœåˆ—è¡¨
            all_episode_results.append(episode_results)
            
            # æ›´æ–°æ€»å¥–åŠ±å’Œæ€»æ­¥æ•°
            total_reward += episode_total_reward
            total_steps += step + 1
            
            print(f"âœ… å›åˆ {episode+1} å®Œæˆ")
            print(f"   å›åˆå¥–åŠ±: {episode_total_reward:.2f}")
            print(f"   å›åˆå¹³å‡å¥–åŠ±: {episode_avg_reward:.4f}")
            print(f"   å›åˆè§¦å‘æ›´æ–°æ¬¡æ•°: {episode_update_count}")
        
        # è®¡ç®—æ‰€æœ‰å›åˆçš„ç»Ÿè®¡æŒ‡æ ‡
        overall_avg_reward = total_reward / total_steps if total_steps > 0 else 0.0
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå›åˆçš„æ•°æ®ä½œä¸ºåŸºç¡€ï¼Œæ·»åŠ æ€»ç»Ÿè®¡ï¼‰
        final_results = all_episode_results[0].copy()
        final_results['all_episodes'] = all_episode_results
        final_results['total_reward'] = total_reward
        final_results['total_steps'] = total_steps
        final_results['avg_reward'] = overall_avg_reward
        final_results['episodes'] = episodes
        
        print(f"\nâœ… åœºæ™¯ {scenario} æµ‹è¯•å®Œæˆ")
        print(f"   æ€»å¥–åŠ±: {total_reward:.2f}")
        print(f"   å¹³å‡å¥–åŠ±: {overall_avg_reward:.4f}")
        print(f"   æ€»æ­¥æ•°: {total_steps}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        if save_results:
            self._save_test_results(final_results)
        
        return final_results
    
    def plot_power_profiles(self, all_results, save_path, show_plot=False):
        """
        ç»˜åˆ¶3ç§åœºæ™¯çš„åŠŸç‡åˆ†é…ç»“æœï¼Œ3è¡Œ1åˆ—å­å›¾ï¼Œå‚è€ƒè¶…çº§ç¯å¢ƒplot_scenario_profilesçš„ç»˜åˆ¶æ–¹å¼
        
        Args:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
            save_path: å›¾åƒä¿å­˜è·¯å¾„
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ
        """
        # å»¶è¿Ÿå¯¼å…¥matplotlib
        matplotlib, plt = setup_matplotlib()
        
        # 3ç§åœºæ™¯çš„é¡ºåºå’Œé…ç½®
        scenarios = [
            ('cruise', 'Long-Endurance Cruise', '#1f77b4'),
            ('recon', 'Cross-Domain Reconnaissance', '#ff7f0e'),
            ('rescue', 'Emergency Rescue', '#2ca02c')
        ]
        
        # é¢œè‰²é…ç½®
        power_colors = {
            'load': '#f09639',  # åŠŸç‡éœ€æ±‚
            'fc': '#c84343',     # ç‡ƒæ–™ç”µæ± 
            'bat': '#42985e',    # ç”µæ± 
            'sc': '#8a7ab5'      # è¶…çº§ç”µå®¹
        }
        
        # åˆ›å»º3è¡Œ1åˆ—å­å›¾ï¼Œå…±äº«Xè½´
        fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)
        fig.suptitle('Fast Adaptation Power Distribution Results', fontsize=18, fontweight='bold', y=0.98)
        
        # å®šä¹‰æ¨¡æ€èƒŒæ™¯è‰²æ˜ å°„
        mode_colors = {
            'air': ('lightblue', 0.1),
            'surface': ('lightyellow', 0.1),
            'underwater': ('lightgreen', 0.1),
            'switch': ('orange', 0.2)
        }
        
        # ç»˜åˆ¶æ¯ä¸ªåœºæ™¯
        for idx, (scenario_type, scenario_label, scenario_color) in enumerate(scenarios):
            ax = axes[idx]
            
            # è·å–å½“å‰åœºæ™¯çš„ç»“æœ
            if scenario_type in all_results:
                scenario_result = all_results[scenario_type]
                
                # å‡†å¤‡æ•°æ®
                times = scenario_result['steps']
                load_demand = scenario_result['load_demand']
                power_fc = scenario_result['power_fc']
                power_bat = scenario_result['power_bat']
                power_sc = scenario_result['power_sc']
                temperature = scenario_result['temperature']
                
                # æ„å»ºæ¨¡æ€é˜¶æ®µä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œæ ¹æ®æ—¶é—´åŒºé—´åˆ’åˆ†ï¼‰
                # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ¨¡æ€åˆ’åˆ†ï¼Œå®é™…åº”è¯¥ä»ç¯å¢ƒä¸­è·å–æ¨¡æ€ä¿¡æ¯
                modes = []
                if scenario_type == 'cruise':
                    # é•¿èˆªæ—¶å·¡èˆªï¼šç©ºä¸­(0-600)â†’åˆ‡æ¢(600-650)â†’æ°´é¢(650-1150)â†’åˆ‡æ¢(1150-1200)â†’ç©ºä¸­(1200-1800)
                    modes = [
                        {'type': 'air', 'start': 0, 'end': 600, 'label': 'Air Flight'},
                        {'type': 'air_to_surface_switch', 'start': 600, 'end': 650, 'label': 'Airâ†’Surface Switch'},
                        {'type': 'surface', 'start': 650, 'end': 1150, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1150, 'end': 1200, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1200, 'end': 1800, 'label': 'Air Flight'}
                    ]
                elif scenario_type == 'recon':
                    # è·¨åŸŸä¾¦å¯Ÿï¼šç©ºä¸­(0-200)â†’åˆ‡æ¢(200-250)â†’æ°´ä¸‹(250-1300)â†’åˆ‡æ¢(1300-1350)â†’æ°´é¢(1350-1550)â†’åˆ‡æ¢(1550-1600)â†’ç©ºä¸­(1600-1800)
                    modes = [
                        {'type': 'air', 'start': 0, 'end': 200, 'label': 'Air Flight'},
                        {'type': 'air_to_underwater_switch', 'start': 200, 'end': 250, 'label': 'Airâ†’Underwater Switch'},
                        {'type': 'underwater', 'start': 250, 'end': 1300, 'label': 'Underwater Navigation'},
                        {'type': 'underwater_to_surface_switch', 'start': 1300, 'end': 1350, 'label': 'Underwaterâ†’Surface Switch'},
                        {'type': 'surface', 'start': 1350, 'end': 1550, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1550, 'end': 1600, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1600, 'end': 1800, 'label': 'Air Flight'}
                    ]
                elif scenario_type == 'rescue':
                    # åº”æ€¥æ•‘æ´ï¼šæ°´é¢(0-320)â†’åˆ‡æ¢(320-370)â†’ç©ºä¸­(370-690)â†’åˆ‡æ¢(690-740)â†’æ°´ä¸‹(740-1060)â†’åˆ‡æ¢(1060-1110)â†’æ°´é¢(1110-1430)â†’åˆ‡æ¢(1430-1480)â†’ç©ºä¸­(1480-1800)
                    modes = [
                        {'type': 'surface', 'start': 0, 'end': 320, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 320, 'end': 370, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 370, 'end': 690, 'label': 'Air Flight'},
                        {'type': 'air_to_underwater_switch', 'start': 690, 'end': 740, 'label': 'Airâ†’Underwater Switch'},
                        {'type': 'underwater', 'start': 740, 'end': 1060, 'label': 'Underwater Navigation'},
                        {'type': 'underwater_to_surface_switch', 'start': 1060, 'end': 1110, 'label': 'Underwaterâ†’Surface Switch'},
                        {'type': 'surface', 'start': 1110, 'end': 1430, 'label': 'Surface Navigation'},
                        {'type': 'surface_to_air_switch', 'start': 1430, 'end': 1480, 'label': 'Surfaceâ†’Air Switch'},
                        {'type': 'air', 'start': 1480, 'end': 1800, 'label': 'Air Flight'}
                    ]
                
                # ç»˜åˆ¶æ¨¡æ€èƒŒæ™¯è‰²
                for mode in modes:
                    # ç¡®å®šæ¨¡æ€ç±»å‹
                    mode_type = mode['type']
                    color, alpha = mode_colors['switch']  # é»˜è®¤åˆ‡æ¢é¢œè‰²
                    if 'air' in mode_type and 'switch' not in mode_type:
                        color, alpha = mode_colors['air']
                    elif 'surface' in mode_type and 'switch' not in mode_type:
                        color, alpha = mode_colors['surface']
                    elif 'underwater' in mode_type and 'switch' not in mode_type:
                        color, alpha = mode_colors['underwater']
                    
                    # ç»˜åˆ¶èƒŒæ™¯è‰²
                    ax.axvspan(mode['start'], mode['end'], alpha=alpha, color=color)
                    
                    # æ·»åŠ æ¨¡æ€æ ‡ç­¾ï¼ˆä»…æ ‡æ³¨ä¸»è¦æ¨¡æ€ï¼‰
                    if 'switch' not in mode_type:
                        mid_time = (mode['start'] + mode['end']) / 2
                        ax.text(mid_time, ax.get_ylim()[1]*0.7, mode['label'], 
                                ha='center', va='center', fontsize=9, fontweight='bold',
                                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
                
                # ç»˜åˆ¶åŠŸç‡æ›²çº¿
                ax.plot(times, load_demand, label='Load Demand', color=power_colors['load'], linewidth=1.2, linestyle='--')
                ax.plot(times, power_fc, label='Fuel Cell', color=power_colors['fc'], linewidth=1.2)
                ax.plot(times, power_bat, label='Battery', color=power_colors['bat'], linewidth=1.2)
                ax.plot(times, power_sc, label='Super Capacitor', color=power_colors['sc'], linewidth=1.2)
                
                # å¡«å……åŠŸç‡åŒºåŸŸ
                ax.fill_between(times, 0, load_demand, color=power_colors['load'], alpha=0.1)
                
                # è®¾ç½®å­å›¾å±æ€§
                ax.set_title(scenario_label, fontsize=14, fontweight='bold', pad=10)
                ax.set_ylabel('Power (W)', fontsize=12, fontweight='bold')
                ax.grid(True, linestyle='--', alpha=0.7)
                ax.set_ylim(0, max(max(load_demand), max(power_fc), max(power_bat), max(power_sc)) * 1.1)
                ax.tick_params(axis='y', labelsize=10)
                
                # ç¾åŒ–è¾¹æ¡†
                ax.spines['top'].set_visible(False)
                
                # åªåœ¨ç¬¬ä¸€ä¸ªå­å›¾æ·»åŠ å›¾ä¾‹
                if idx == 0:
                    ax.legend(loc='upper right', fontsize=10, ncol=2)
            else:
                ax.set_title(scenario_label, fontsize=14, fontweight='bold', pad=10)
                ax.set_ylabel('Power (W)', fontsize=12, fontweight='bold')
                ax.grid(True, linestyle='--', alpha=0.7)
                ax.spines['top'].set_visible(False)
        
        # è®¾ç½®å…±äº«Xè½´æ ‡ç­¾
        axes[-1].set_xlabel('Time (s)', fontsize=14, fontweight='bold')
        axes[-1].set_xlim(0, 1800)  # è®¾ç½®ä¸º1800s
        axes[-1].set_xticks(np.arange(0, 1801, 200))  # æ¯200sä¸€ä¸ªåˆ»åº¦
        axes[-1].tick_params(axis='x', labelsize=10)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout(rect=[0, 0.03, 1, 0.97])
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(save_path, dpi=1200, bbox_inches='tight')
        print(f"âœ… åŠŸç‡åˆ†é…ç»“æœå›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        # æ˜¾ç¤ºå›¾åƒï¼ˆå¯é€‰ï¼‰
        if show_plot:
            plt.show()
        else:
            plt.close()
    
    def test_all_scenarios(self, max_steps=1000, save_results=True, show_plot=False, episodes=1):
        """
        æµ‹è¯•æŒ‡å®šçš„ä¸‰ä¸ªç¯å¢ƒ
        
        Args:
            max_steps: æœ€å¤§æµ‹è¯•æ­¥æ•°
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ
            episodes: æµ‹è¯•å›åˆæ•°
        
        Returns:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
        """
        # åªæµ‹è¯•æŒ‡å®šçš„ä¸‰ä¸ªç¯å¢ƒ
        scenarios = ['cruise', 'recon', 'rescue']
        
        # æµ‹è¯•æ‰€æœ‰åœºæ™¯
        all_results = {}
        for scenario in scenarios:
            results = self.test_single_scenario(scenario, max_steps, save_results, episodes)
            all_results[scenario] = results
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        if save_results:
            self._save_summary_results(all_results)
            
            # ç»˜åˆ¶åŠŸç‡åˆ†é…å›¾åƒ
            results_dir = os.path.join(
                os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
                self.timestamp
            )
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(results_dir, exist_ok=True)
            plot_path = os.path.join(results_dir, "power_distribution_3_scenarios.svg")
            self.plot_power_profiles(all_results, plot_path, show_plot)
        
        return all_results
    
    def _save_test_results(self, results):
        """
        ä¿å­˜æµ‹è¯•ç»“æœ
        
        Args:
            results: æµ‹è¯•ç»“æœ
        """
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„timestampï¼‰
        results_dir = os.path.join(
            os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
            self.timestamp
        )
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜å•ä¸ªåœºæ™¯ç»“æœ
        scenario = results['scenario']
        result_path = os.path.join(results_dir, f"fast_adaptation_result_{scenario}.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, cls=NumpyEncoder, indent=4)
        
        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_path}")
    
    def _save_summary_results(self, all_results):
        """
        ä¿å­˜æ±‡æ€»æµ‹è¯•ç»“æœ
        
        Args:
            all_results: æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
        """
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„timestampï¼‰
        results_dir = os.path.join(
            os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
            self.timestamp
        )
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_path = os.path.join(results_dir, "fast_adaptation_summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, cls=NumpyEncoder, indent=4)
        
        # ä¿å­˜è¶…å‚æ•°
        hyperparams_path = os.path.join(results_dir, "fast_adaptation_hyperparams.json")
        with open(hyperparams_path, 'w', encoding='utf-8') as f:
            json.dump(self.hyperparams, f, cls=NumpyEncoder, indent=4)
        
        print(f"ğŸ“Š æ±‡æ€»ç»“æœå·²ä¿å­˜åˆ°: {summary_path}")
        print(f"ğŸ“‹ è¶…å‚æ•°å·²ä¿å­˜åˆ°: {hyperparams_path}")
    
    def save_model(self, save_path):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
        """
        torch.save(self.model.state_dict(), save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='å¿«å­¦ä¹ /å¿«æµ‹è¯•è„šæœ¬')
    
    # æ ¸å¿ƒå‚æ•°
    parser.add_argument('--model-path', type=str, required=True,
                        help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--hyperparams-path', type=str, default=None,
                        help='å¿«å­¦ä¹ è¶…å‚æ•°è·¯å¾„')
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument('--scenario', type=str, default=None,
                        help='æµ‹è¯•åœºæ™¯åç§°ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰åœºæ™¯ï¼‰')
    parser.add_argument('--episodes', type=int, default=1,
                        help='æµ‹è¯•å›åˆæ•°ï¼ˆé»˜è®¤ï¼š1ï¼‰')
    parser.add_argument('--max-steps', type=int, default=1000,
                        help='æ¯ä¸ªåœºæ™¯çš„æœ€å¤§æµ‹è¯•æ­¥æ•°')
    parser.add_argument('--save-results', action='store_true',
                        help='æ˜¯å¦ä¿å­˜æµ‹è¯•ç»“æœ')
    parser.add_argument('--show-plot', action='store_true',
                        help='æ˜¯å¦æ˜¾ç¤ºæµ‹è¯•ç»“æœå›¾ï¼ˆé»˜è®¤ï¼šä»…ä¿å­˜ä¸æ˜¾ç¤ºï¼‰')
    
    # è‡ªå®šä¹‰è¶…å‚æ•°
    parser.add_argument('--lr', type=float, default=None,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--kl-threshold', type=float, default=None,
                        help='KLæ•£åº¦é˜ˆå€¼')
    parser.add_argument('--window-size', type=int, default=None,
                        help='æ»‘åŠ¨çª—å£å¤§å°')
    
    return parser.parse_args()

def main():
    """
    ä¸»å‡½æ•°
    """
    args = parse_args()
    
    # æ„å»ºè‡ªå®šä¹‰è¶…å‚æ•°
    custom_hyperparams = {}
    if args.lr:
        custom_hyperparams['lr'] = args.lr
    if args.kl_threshold:
        custom_hyperparams['kl_threshold'] = args.kl_threshold
    if args.window_size:
        custom_hyperparams['window_size'] = args.window_size
    
    # åˆå§‹åŒ–å¿«å­¦ä¹ è®­ç»ƒå™¨
    trainer = FastAdaptationTrainer(
        model_path=args.model_path,
        hyperparams_path=args.hyperparams_path,
        custom_hyperparams=custom_hyperparams
    )
    
    # æµ‹è¯•åœºæ™¯
    if args.scenario:
        # æµ‹è¯•å•ä¸ªåœºæ™¯
        results = trainer.test_single_scenario(
            scenario=args.scenario,
            max_steps=args.max_steps,
            save_results=args.save_results,
            episodes=args.episodes
        )
        
        # å¦‚æœä¿å­˜ç»“æœï¼Œç»˜åˆ¶å•ä¸ªåœºæ™¯çš„åŠŸç‡åˆ†é…å›¾åƒ
        if args.save_results:
            # ç»˜åˆ¶å•ä¸ªåœºæ™¯çš„åŠŸç‡åˆ†é…å›¾åƒ
            results_dir = os.path.join(
                os.path.abspath(os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')),
                trainer.timestamp
            )
            plot_path = os.path.join(results_dir, f"power_distribution_{args.scenario}.svg")
            
            # åˆ›å»ºå•ä¸ªåœºæ™¯çš„ç»“æœå­—å…¸
            single_result = {args.scenario: results}
            
            # è°ƒç”¨ç»˜å›¾å‡½æ•°
            trainer.plot_power_profiles(single_result, plot_path, show_plot=args.show_plot)
    else:
        # æµ‹è¯•æ‰€æœ‰åœºæ™¯
        trainer.test_all_scenarios(
            max_steps=args.max_steps,
            save_results=args.save_results,
            show_plot=args.show_plot,
            episodes=args.episodes
        )
    
    print(f"\n=== å¿«å­¦ä¹ /å¿«æµ‹è¯•å®Œæˆ ===")

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæµ‹è¯•è„šæœ¬ï¼šæµ‹è¯•ä¸åŒç« èŠ‚çš„æ™ºèƒ½ä½“åœ¨è¶…çº§ç¯å¢ƒä¸­çš„è¡¨ç°

åŠŸèƒ½ï¼š
1. æ”¯æŒæµ‹è¯•Chapter3å’ŒChapter4çš„æ™ºèƒ½ä½“
2. å…¼å®¹ç¬¬äº”ç« çš„æ…¢å­¦ä¹ å’Œåç»­çš„å¿«å­¦ä¹ 
3. æ”¯æŒåœ¨è¶…çº§ç¯å¢ƒçš„æ‰€æœ‰åœºæ™¯ä¸­æµ‹è¯•
4. ç”ŸæˆæŸ±çŠ¶å›¾å¯¹æ¯”ä¸åŒç­–ç•¥çš„è¡¨ç°
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from Scripts.Chapter5.Env_Ultra import EnvUltra
from Scripts.Chapter5.baseline_strategies import BaselineStrategies

def test_baseline_strategy(strategy_name, env, episodes=1):
    """
    æµ‹è¯•åŸºå‡†ç­–ç•¥
    
    Args:
        strategy_name: ç­–ç•¥åç§° ('rule_based')
        env: ç¯å¢ƒå®ä¾‹
        episodes: æµ‹è¯•å›åˆæ•°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
    """
    strategies = BaselineStrategies(env)
    total_reward = 0.0
    total_steps = 0
    
    for episode in range(episodes):
        state = env.reset()
        done = False
        episode_reward = 0.0
        episode_steps = 0
        
        while not done:
            if strategy_name == 'rule_based':
                action_list = strategies.rule_based_strategy(state)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åŸºå‡†ç­–ç•¥: {strategy_name}")
            
            next_state, reward, done, info = env.step(action_list)
            episode_reward += reward
            episode_steps += 1
            state = next_state
        
        total_reward += episode_reward
        total_steps += episode_steps
    
    avg_reward = total_reward / episodes
    avg_steps = total_steps / episodes
    
    return avg_reward, avg_steps

def test_chapter3_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•Chapter3çš„å¤šæ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter3çš„æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ ç­–ç•¥-ç¯å¢ƒæ–‡ä»¶å¤¹è·¯å¾„
        if output_dir and strategy_name:
            strategy_env_dir = os.path.join(output_dir, strategy_name, env.scenario_type)
            os.makedirs(strategy_env_dir, exist_ok=True)
        else:
            strategy_env_dir = output_dir
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        chapter3_test_script = os.path.join(os.path.dirname(__file__), '../Chapter3/test.py')
        cmd = [
            sys.executable, chapter3_test_script,
            '--net-date', '1218',
            '--train-id', '36',
            '--use-ultra-env',
            '--scenario', env.scenario_type
            # ç§»é™¤--show-plot falseï¼Œä½¿ç”¨é»˜è®¤å€¼
        ]
        
        # æ·»åŠ --save-dirå‚æ•°
        if strategy_env_dir:
            cmd.extend(['--save-dir', strategy_env_dir])
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡ŒChapter3æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… Chapter3æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­è¯»å–å¥–åŠ±ä¿¡æ¯
            json_file_path = os.path.join(strategy_env_dir, "MARL_Model_Test_Results.json")
            if os.path.exists(json_file_path):
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    test_results = json.load(f)
                total_reward = test_results['core_metrics']['total_reward']
                total_steps = test_results['time_metrics']['total_steps']
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
                return total_reward, total_steps
            else:
                print(f"è­¦å‘Š: æµ‹è¯•ç»“æœJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ Chapter3æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: Chapter3æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_chapter4_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•Chapter4çš„è”åˆç½‘ç»œæ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter4çš„æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ ç­–ç•¥-ç¯å¢ƒæ–‡ä»¶å¤¹è·¯å¾„
        if output_dir and strategy_name:
            strategy_env_dir = os.path.join(output_dir, strategy_name, env.scenario_type)
            os.makedirs(strategy_env_dir, exist_ok=True)
        else:
            strategy_env_dir = output_dir
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        chapter4_test_script = os.path.join(os.path.dirname(__file__), '../Chapter4/test_Joint.py')
        cmd = [
            sys.executable, chapter4_test_script,
            '--net-date', '1223',
            '--train-id', '2',
            '--use-ultra-env',
            '--scenario', env.scenario_type
            # ç§»é™¤--show-plot falseï¼Œä½¿ç”¨é»˜è®¤å€¼
        ]
        
        # æ·»åŠ --save-dirå‚æ•°
        if strategy_env_dir:
            cmd.extend(['--save-dir', strategy_env_dir])
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡ŒChapter4æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… Chapter4æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­è¯»å–å¥–åŠ±ä¿¡æ¯
            json_file_path = os.path.join(strategy_env_dir, "Joint_Model_Test_Results.json")
            if os.path.exists(json_file_path):
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    test_results = json.load(f)
                total_reward = test_results['core_metrics']['total_reward']
                total_steps = test_results['time_metrics']['total_steps']
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
                return total_reward, total_steps
            else:
                print(f"è­¦å‘Š: æµ‹è¯•ç»“æœJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ Chapter4æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: Chapter4æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_slow_learning_agent(env, agent_path, episodes=1):
    """
    æµ‹è¯•ç¬¬äº”ç« çš„æ…¢å­¦ä¹ æ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter5çš„æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        slow_test_script = os.path.join(os.path.dirname(__file__), 'test_slow_training.py')
        
        # æ£€æŸ¥æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬æ˜¯å¦å­˜åœ¨
        if not os.path.exists(slow_test_script):
            print(f"è­¦å‘Š: æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
            return test_baseline_strategy('rule_based', env, episodes)
        
        # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
        cmd = [
            sys.executable, slow_test_script
        ]
        
        # æ·»åŠ æ¨¡å‹è·¯å¾„ï¼ˆå¿…é¡»å‚æ•°ï¼‰
        if agent_path:
            cmd.extend(['--model-path', agent_path])
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„
            default_model_path = os.path.join(os.path.dirname(__file__), '../../nets/Chap5/slow_learning/model.pth')
            cmd.extend(['--model-path', default_model_path])
            print(f"è­¦å‘Š: æœªæä¾›æ…¢å­¦ä¹ æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {default_model_path}")
        
        # æ·»åŠ åœºæ™¯å‚æ•°ï¼ˆå¦‚æœæ”¯æŒçš„è¯ï¼‰
        # æ£€æŸ¥test_slow_training.pyæ˜¯å¦æ”¯æŒ--scenarioå‚æ•°
        # test_slow_training.pyä¸æ”¯æŒ--scenarioå‚æ•°ï¼Œè·³è¿‡è¯¥å‚æ•°
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡Œæ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            # è¿™é‡Œéœ€è¦ä»è¾“å‡ºä¸­æå–å¥–åŠ±ä¿¡æ¯
            # ç”±äºtest_slow_training.pyæ²¡æœ‰è¿”å›å¥–åŠ±ä¿¡æ¯ï¼Œæš‚æ—¶ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿
            print(f"è­¦å‘Š: æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•ç»“æœè§£æåŠŸèƒ½å°šæœªå®ç°ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_fast_learning_agent(env, agent_path, episodes=1):
    """
    æµ‹è¯•ç¬¬äº”ç« çš„å¿«å­¦ä¹ æ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
    """
    print(f"è­¦å‘Š: å¿«å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•åŠŸèƒ½å°šæœªå®ç°ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
    return test_baseline_strategy('rule_based', env, episodes)

def run_comprehensive_test():
    """
    è¿è¡Œç»¼åˆæµ‹è¯•
    """
    # å¯¼å…¥å¤šçº¿ç¨‹åº“
    import concurrent.futures
    
    # å®šä¹‰æµ‹è¯•åœºæ™¯
    scenarios = EnvUltra.SCENARIO_TYPES
    
    # å®šä¹‰æµ‹è¯•ç­–ç•¥
    strategies = [
        {'name': 'Rule-Based', 'type': 'baseline', 'path': None},
        {'name': 'Chapter3 MARL', 'type': 'chapter3', 'path': '/home/siyu/Master_Code/nets/Chap3/1218/36'},
        {'name': 'Chapter4 Joint Net', 'type': 'chapter4', 'path': '/home/siyu/Master_Code/nets/Chap4/Joint_Net/1223/2'},
        {'name': 'Slow Learning', 'type': 'slow_learning', 'path': None},
        {'name': 'Fast Learning', 'type': 'fast_learning', 'path': None}
    ]
    
    # æµ‹è¯•å‚æ•°
    episodes = 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%m%d_%H%M%S")
    output_dir = os.path.join('/home/siyu/Master_Code/nets/Chap5', 'comprehensive_test_results', timestamp)
    os.makedirs(output_dir, exist_ok=True)
    
    # å®šä¹‰æµ‹è¯•ä»»åŠ¡å‡½æ•°
    def test_task(scenario, strategy):
        """
        å•ä¸ªæµ‹è¯•ä»»åŠ¡
        
        Args:
            scenario: æµ‹è¯•åœºæ™¯
            strategy: æµ‹è¯•ç­–ç•¥
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print(f"\n--- æµ‹è¯•ç­–ç•¥: {strategy['name']}ï¼Œåœºæ™¯: {scenario} ---")
        
        # åˆ›å»ºç¯å¢ƒ
        env = EnvUltra(scenario_type=scenario)
        
        # æ ¹æ®ç­–ç•¥ç±»å‹é€‰æ‹©æµ‹è¯•å‡½æ•°
        if strategy['type'] == 'baseline':
            avg_reward, avg_steps = test_baseline_strategy('rule_based', env, episodes)
        elif strategy['type'] == 'chapter3':
            avg_reward, avg_steps = test_chapter3_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        elif strategy['type'] == 'chapter4':
            avg_reward, avg_steps = test_chapter4_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        elif strategy['type'] == 'slow_learning':
            avg_reward, avg_steps = test_slow_learning_agent(env, strategy['path'], episodes)
        elif strategy['type'] == 'fast_learning':
            avg_reward, avg_steps = test_fast_learning_agent(env, strategy['path'], episodes)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç­–ç•¥ç±»å‹: {strategy['type']}")
        
        print(f"ç­–ç•¥: {strategy['name']}ï¼Œåœºæ™¯: {scenario} æµ‹è¯•å®Œæˆ")
        print(f"å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        print(f"å¹³å‡æ­¥æ•°: {avg_steps:.2f}")
        
        # è¿”å›æµ‹è¯•ç»“æœ
        return {
            'scenario': scenario,
            'strategy': strategy['name'],
            'avg_reward': avg_reward,
            'avg_steps': avg_steps
        }
    
    # å­˜å‚¨æµ‹è¯•ç»“æœ
    results = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        future_to_task = {}
        for scenario in scenarios:
            for strategy in strategies:
                future = executor.submit(test_task, scenario, strategy)
                future_to_task[future] = (scenario, strategy['name'])
        
        # æ”¶é›†æµ‹è¯•ç»“æœ
        for future in concurrent.futures.as_completed(future_to_task):
            scenario, strategy_name = future_to_task[future]
            try:
                task_result = future.result()
                results.append(task_result)
            except Exception as e:
                print(f"ç­–ç•¥: {strategy_name}ï¼Œåœºæ™¯: {scenario} æµ‹è¯•å¤±è´¥: {e}")
    
    return results, output_dir

def plot_comparison(results, output_dir):
    """
    ç»˜åˆ¶ä¸åŒç­–ç•¥åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å¥–åŠ±å¯¹æ¯”æŸ±çŠ¶å›¾
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    # æå–å”¯ä¸€çš„åœºæ™¯å’Œç­–ç•¥
    scenarios = sorted(list(set(r['scenario'] for r in results)))
    strategies = sorted(list(set(r['strategy'] for r in results)))
    
    # å‡†å¤‡æ•°æ®
    data = {}
    for scenario in scenarios:
        data[scenario] = {}
        for strategy in strategies:
            # æŸ¥æ‰¾å¯¹åº”ç»“æœ
            for r in results:
                if r['scenario'] == scenario and r['strategy'] == strategy:
                    data[scenario][strategy] = r['avg_reward']
                    break
    
    # åˆ›å»ºå›¾è¡¨
    num_scenarios = len(scenarios)
    num_strategies = len(strategies)
    
    fig, ax = plt.subplots(figsize=(15, 8))
    
    # è®¾ç½®æŸ±çŠ¶å›¾å®½åº¦å’Œä½ç½®
    bar_width = 0.15
    x = np.arange(num_scenarios)
    
    # ä¸ºæ¯ä¸ªç­–ç•¥ç»˜åˆ¶æŸ±çŠ¶å›¾
    for i, strategy in enumerate(strategies):
        rewards = [data[scenario][strategy] for scenario in scenarios]
        ax.bar(x + i * bar_width, rewards, bar_width, label=strategy)
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Scene')
    ax.set_ylabel('Average Reward')
    ax.set_title('Performance Comparison of Different Strategies Across Super Environments')
    ax.set_xticks(x + bar_width * (num_strategies - 1) / 2)
    ax.set_xticklabels(scenarios, rotation=45, ha='right')
    ax.legend()
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    fig_path = os.path.join(output_dir, 'strategy_comparison.png')
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    print(f"\n=== å›¾è¡¨å·²ä¿å­˜åˆ°: {fig_path} ===")
    
    # ä¿å­˜ç»“æœæ•°æ®
    results_path = os.path.join(output_dir, 'test_results.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=4, ensure_ascii=False)
    print(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    plt.close()

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=== å¼€å§‹ç»¼åˆæµ‹è¯• ===")
    
    # è¿è¡Œæµ‹è¯•
    results, output_dir = run_comprehensive_test()
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾
    plot_comparison(results, output_dir)
    
    print("\n=== ç»¼åˆæµ‹è¯•å®Œæˆ ===")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæµ‹è¯•è„šæœ¬ï¼šæµ‹è¯•ä¸åŒç« èŠ‚çš„æ™ºèƒ½ä½“åœ¨è¶…çº§ç¯å¢ƒä¸­çš„è¡¨ç°

åŠŸèƒ½ï¼š
1. æ”¯æŒæµ‹è¯•Chapter3å’ŒChapter4çš„æ™ºèƒ½ä½“
2. å…¼å®¹ç¬¬äº”ç« çš„æ…¢å­¦ä¹ å’Œåç»­çš„å¿«å­¦ä¹ 
3. æ”¯æŒåœ¨è¶…çº§ç¯å¢ƒçš„æ‰€æœ‰åœºæ™¯ä¸­æµ‹è¯•
4. ç”ŸæˆæŸ±çŠ¶å›¾å¯¹æ¯”ä¸åŒç­–ç•¥çš„è¡¨ç°
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from Scripts.Chapter5.Env_Ultra import EnvUltra
from Scripts.Chapter5.baseline_strategies import BaselineStrategies

def test_baseline_strategy(strategy_name, env, episodes=1):
    """
    æµ‹è¯•åŸºå‡†ç­–ç•¥
    
    Args:
        strategy_name: ç­–ç•¥åç§° ('rule_based')
        env: ç¯å¢ƒå®ä¾‹
        episodes: æµ‹è¯•å›åˆæ•°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
        power_matching_percent: åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯”
        avg_decision_time_ms: å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    """
    import time
    strategies = BaselineStrategies(env)
    total_reward = 0.0
    total_steps = 0
    total_unmatched_power = 0.0
    total_demand_power = 0.0
    total_decision_time = 0.0
    
    for episode in range(episodes):
        state = env.reset()
        done = False
        episode_reward = 0.0
        episode_steps = 0
        episode_unmatched_power = 0.0
        episode_demand_power = 0.0
        episode_decision_time = 0.0
        
        while not done:
            # è®°å½•å†³ç­–å¼€å§‹æ—¶é—´
            decision_start = time.time()
            
            if strategy_name == 'rule_based':
                action_list = strategies.rule_based_strategy(state)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åŸºå‡†ç­–ç•¥: {strategy_name}")
            
            # è®¡ç®—å†³ç­–è€—æ—¶
            decision_time = time.time() - decision_start
            episode_decision_time += decision_time
            
            next_state, reward, done, info = env.step(action_list)
            
            # è®¡ç®—åŠŸç‡ä¸åŒ¹é…åº¦
            P_load = info['P_load']
            P_fc = info['P_fc']
            P_bat = info['P_bat']
            P_sc = info['P_sc']
            
            total_demand = abs(P_load)
            unmatched_power = abs(P_load - (P_fc + P_bat + P_sc))
            
            episode_unmatched_power += unmatched_power
            episode_demand_power += total_demand if total_demand > 0 else 1e-6
            
            episode_reward += reward
            episode_steps += 1
            state = next_state
        
        total_reward += episode_reward
        total_steps += episode_steps
        total_unmatched_power += episode_unmatched_power
        total_demand_power += episode_demand_power
        total_decision_time += episode_decision_time
    
    avg_steps = total_steps / episodes
    avg_reward = total_reward / episodes / avg_steps
    
    # è®¡ç®—åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯” (1 - ä¸åŒ¹é…åŠŸç‡/æ€»éœ€æ±‚åŠŸç‡) * 100%
    if total_demand_power > 0:
        power_matching_percent = (1 - total_unmatched_power / total_demand_power) * 100
    else:
        power_matching_percent = 0.0
    
    # è®¡ç®—å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    avg_decision_time_ms = (total_decision_time / total_steps) * 1000 if total_steps > 0 else 0.0
    
    return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms

def test_chapter3_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•Chapter3çš„å¤šæ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
        power_matching_percent: åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯”
        avg_decision_time_ms: å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter3çš„æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ ç­–ç•¥-ç¯å¢ƒæ–‡ä»¶å¤¹è·¯å¾„
        if output_dir and strategy_name:
            strategy_env_dir = os.path.join(output_dir, strategy_name, env.scenario_type)
            os.makedirs(strategy_env_dir, exist_ok=True)
        else:
            strategy_env_dir = output_dir
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        chapter3_test_script = os.path.join(os.path.dirname(__file__), '../Chapter3/test.py')
        cmd = [
            sys.executable, chapter3_test_script,
            '--net-date', '1218',
            '--train-id', '36',
            '--use-ultra-env',
            '--scenario', env.scenario_type
            # ç§»é™¤--show-plot falseï¼Œä½¿ç”¨é»˜è®¤å€¼
        ]
        
        # æ·»åŠ --save-dirå‚æ•°
        if strategy_env_dir:
            cmd.extend(['--save-dir', strategy_env_dir])
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡ŒChapter3æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… Chapter3æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­è¯»å–å¥–åŠ±ä¿¡æ¯
            json_file_path = os.path.join(strategy_env_dir, "MARL_Model_Test_Results.json")
            if os.path.exists(json_file_path):
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    test_results = json.load(f)
                
                # æå–æ ¸å¿ƒæŒ‡æ ‡
                total_reward = test_results['core_metrics']['total_reward']
                total_steps = test_results['time_metrics']['total_steps']
                
                # è®¡ç®—åŠŸç‡åŒ¹é…åº¦
                power_matching_data = test_results.get('power_matching', {})
                total_unmatched_power = power_matching_data.get('total_unmatched_power_w_step', 0)
                total_load_demand = power_matching_data.get('total_load_demand_w_step', 1e-6)
                power_matching_percent = (1 - total_unmatched_power / total_load_demand) * 100 if total_load_demand > 0 else 0.0
                
                # è·å–å¹³å‡å†³ç­–è€—æ—¶ï¼ˆåŠ¨ä½œé€‰æ‹©æ—¶é—´ï¼‰
                time_metrics = test_results.get('time_metrics', {})
                phase_time_breakdown = time_metrics.get('phase_time_breakdown_s', {})
                total_action_time_s = phase_time_breakdown.get('Action_Select', 0.0)
                avg_decision_time_ms = (total_action_time_s / total_steps) * 1000 if total_steps > 0 else 0.0
                
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
                print(f"ğŸ“Š åŠŸç‡åŒ¹é…åº¦: {power_matching_percent:.2f}%")
                print(f"ğŸ“Š å¹³å‡å†³ç­–è€—æ—¶: {avg_decision_time_ms:.4f} ms")
                
                # æ ¹æ®episodesè®¡ç®—å¹³å‡æ­¥æ•°å’Œå•æ­¥å¹³å‡å¥–åŠ±
                avg_steps = total_steps / episodes
                avg_reward = total_reward / episodes / avg_steps
                return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms
            else:
                print(f"è­¦å‘Š: æµ‹è¯•ç»“æœJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ Chapter3æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: Chapter3æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_chapter4_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•Chapter4çš„è”åˆç½‘ç»œæ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
        power_matching_percent: åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯”
        avg_decision_time_ms: å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter4çš„æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ ç­–ç•¥-ç¯å¢ƒæ–‡ä»¶å¤¹è·¯å¾„
        if output_dir and strategy_name:
            strategy_env_dir = os.path.join(output_dir, strategy_name, env.scenario_type)
            os.makedirs(strategy_env_dir, exist_ok=True)
        else:
            strategy_env_dir = output_dir
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        chapter4_test_script = os.path.join(os.path.dirname(__file__), '../Chapter4/test_Joint.py')
        cmd = [
            sys.executable, chapter4_test_script,
            '--net-date', '1223',
            '--train-id', '2',
            '--use-ultra-env',
            '--scenario', env.scenario_type
            # ç§»é™¤--show-plot falseï¼Œä½¿ç”¨é»˜è®¤å€¼
        ]
        
        # æ·»åŠ --save-dirå‚æ•°
        if strategy_env_dir:
            cmd.extend(['--save-dir', strategy_env_dir])
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡ŒChapter4æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… Chapter4æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­è¯»å–å¥–åŠ±ä¿¡æ¯
            json_file_path = os.path.join(strategy_env_dir, "Joint_Model_Test_Results.json")
            if os.path.exists(json_file_path):
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    test_results = json.load(f)
                
                # æå–æ ¸å¿ƒæŒ‡æ ‡
                total_reward = test_results['core_metrics']['total_reward']
                total_steps = test_results['time_metrics']['total_steps']
                
                # è®¡ç®—åŠŸç‡åŒ¹é…åº¦
                power_matching_data = test_results.get('power_matching', {})
                total_unmatched_power = power_matching_data.get('total_unmatched_power_w_step', 0)
                total_load_demand = power_matching_data.get('total_load_demand_w_step', 1e-6)
                power_matching_percent = (1 - total_unmatched_power / total_load_demand) * 100 if total_load_demand > 0 else 0.0
                
                # è·å–å¹³å‡å†³ç­–è€—æ—¶ï¼ˆåŠ¨ä½œé€‰æ‹©æ—¶é—´ï¼‰
                time_metrics = test_results.get('time_metrics', {})
                phase_time_breakdown = time_metrics.get('phase_time_breakdown_s', {})
                total_action_time_s = phase_time_breakdown.get('Action_Select', 0.0)
                avg_decision_time_ms = (total_action_time_s / total_steps) * 1000 if total_steps > 0 else 0.0
                
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
                print(f"ğŸ“Š åŠŸç‡åŒ¹é…åº¦: {power_matching_percent:.2f}%")
                print(f"ğŸ“Š å¹³å‡å†³ç­–è€—æ—¶: {avg_decision_time_ms:.4f} ms")
                
                # æ ¹æ®episodesè®¡ç®—å¹³å‡æ­¥æ•°å’Œå•æ­¥å¹³å‡å¥–åŠ±
                avg_steps = total_steps / episodes
                avg_reward = total_reward / episodes / avg_steps
                return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms
            else:
                print(f"è­¦å‘Š: æµ‹è¯•ç»“æœJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ Chapter4æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: Chapter4æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_slow_learning_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•ç¬¬äº”ç« çš„æ…¢å­¦ä¹ æ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
        power_matching_percent: åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯”
        avg_decision_time_ms: å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter5çš„æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        slow_test_script = os.path.join(os.path.dirname(__file__), 'test_slow_training.py')
        
        # æ£€æŸ¥æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬æ˜¯å¦å­˜åœ¨
        if not os.path.exists(slow_test_script):
            print(f"è­¦å‘Š: æ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
            return test_baseline_strategy('rule_based', env, episodes)
        
        # æ„é€ ç­–ç•¥æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¸åŒ…å«åœºæ™¯ï¼Œé¿å…æ¯ä¸ªåœºæ™¯éƒ½ç”Ÿæˆä¾§è§†å›¾ï¼‰
        if output_dir and strategy_name:
            strategy_dir = os.path.join(output_dir, strategy_name)
            os.makedirs(strategy_dir, exist_ok=True)
        else:
            strategy_dir = output_dir
        
        # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
        cmd = [
            sys.executable, slow_test_script,
            '--max-steps', '1800',   # ä½¿ç”¨1800æ­¥æµ‹è¯•
            '--episodes', str(episodes),  # æ·»åŠ å›åˆæ•°å‚æ•°
            '--save-dir', strategy_dir,  # ä¿å­˜åˆ°ç­–ç•¥ç›®å½•ï¼Œè€Œä¸æ˜¯ç­–ç•¥-åœºæ™¯ç›®å½•
            # ä¸æ·»åŠ --show-plotå‚æ•°ï¼Œé»˜è®¤ä¸æ˜¾ç¤ºå›¾åƒ
        ]
        
        # æ·»åŠ æ¨¡å‹è·¯å¾„ï¼ˆå¿…é¡»å‚æ•°ï¼‰
        if agent_path:
            cmd.extend(['--model-path', agent_path])
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„
            default_model_path = os.path.join(os.path.dirname(__file__), '../../nets/Chap5/slow_training/model.pth')
            cmd.extend(['--model-path', default_model_path])
            print(f"è­¦å‘Š: æœªæä¾›æ…¢å­¦ä¹ æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {default_model_path}")
        
        # åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶ç”Ÿæˆ9åœºæ™¯ä¾§è§†å›¾
        # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡ä¾§è§†å›¾
        side_view_path = os.path.join(strategy_dir, "power_distribution_9_scenarios.svg")
        if not os.path.exists(side_view_path):
            print(f"è¿è¡Œæ…¢å­¦ä¹ æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True)
        else:
            print(f"æ…¢å­¦ä¹ 9åœºæ™¯ä¾§è§†å›¾å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
            # ç›´æ¥è¯»å–å·²æœ‰çš„æµ‹è¯•ç»“æœ
            result = None
        
        # è§£ææµ‹è¯•ç»“æœ
        if result is not None and result.returncode == 0:
            print(f"âœ… æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
        
        # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­è¯»å–å¥–åŠ±ä¿¡æ¯
        scenario_json_path = os.path.join(strategy_dir, f"test_result_{env.scenario_type}.json")
        if os.path.exists(scenario_json_path):
            with open(scenario_json_path, 'r', encoding='utf-8') as f:
                test_results = json.load(f)
            total_reward = test_results['total_reward']
            total_steps = test_results['total_steps']
            
            # è®¡ç®—åŠŸç‡åŒ¹é…åº¦
            total_unmatched_power = test_results.get('total_unmatched_power', 0)
            total_demand_power = test_results.get('total_demand_power', 1e-6)
            power_matching_percent = (1 - total_unmatched_power / total_demand_power) * 100 if total_demand_power > 0 else 0.0
            
            # è·å–å¹³å‡å†³ç­–è€—æ—¶ï¼ˆå¦‚æœæ–‡ä»¶ä¸­æ²¡æœ‰ï¼Œé»˜è®¤ä¸º0ï¼‰
            avg_decision_time_ms = test_results.get('avg_decision_time_ms', 0.0)
            
            print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
            print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
            print(f"ğŸ“Š åŠŸç‡åŒ¹é…åº¦: {power_matching_percent:.2f}%")
            print(f"ğŸ“Š å¹³å‡å†³ç­–è€—æ—¶: {avg_decision_time_ms:.4f} ms")
            
            # æ ¹æ®episodesè®¡ç®—å¹³å‡æ­¥æ•°å’Œå•æ­¥å¹³å‡å¥–åŠ±
            avg_steps = total_steps / episodes if total_steps > 0 else 0.0
            avg_reward = total_reward / episodes / avg_steps if avg_steps > 0 else 0.0
            return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms
        else:
            print(f"è­¦å‘Š: æµ‹è¯•ç»“æœJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
            return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: æ…¢å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def test_fast_learning_agent(env, agent_path, episodes=1, output_dir=None, strategy_name=None):
    """
    æµ‹è¯•ç¬¬äº”ç« çš„å¿«å­¦ä¹ æ™ºèƒ½ä½“
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        agent_path: æ™ºèƒ½ä½“æ¨¡å‹è·¯å¾„
        episodes: æµ‹è¯•å›åˆæ•°
        output_dir: è¾“å‡ºç›®å½•
        strategy_name: ç­–ç•¥åç§°
    
    Returns:
        avg_reward: å¹³å‡å¥–åŠ±
        avg_steps: å¹³å‡æ­¥æ•°
        power_matching_percent: åŠŸç‡åŒ¹é…åº¦ç™¾åˆ†æ¯”
        avg_decision_time_ms: å¹³å‡å†³ç­–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    """
    try:
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè°ƒç”¨Chapter5çš„å¿«å­¦ä¹ æµ‹è¯•è„šæœ¬
        import subprocess
        import sys
        import os
        import json
        
        # æ„é€ å‘½ä»¤è¡Œå‚æ•°
        fast_test_script = os.path.join(os.path.dirname(__file__), 'fast_adaptation.py')
        
        # æ£€æŸ¥å¿«å­¦ä¹ æµ‹è¯•è„šæœ¬æ˜¯å¦å­˜åœ¨
        if not os.path.exists(fast_test_script):
            print(f"è­¦å‘Š: å¿«å­¦ä¹ æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
            return test_baseline_strategy('rule_based', env, episodes)
        
        # æ„é€ ç­–ç•¥-ç¯å¢ƒæ–‡ä»¶å¤¹è·¯å¾„
        if output_dir and strategy_name:
            strategy_env_dir = os.path.join(output_dir, strategy_name, env.scenario_type)
            os.makedirs(strategy_env_dir, exist_ok=True)
        else:
            strategy_env_dir = output_dir
        
        # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
        cmd = [
            sys.executable, fast_test_script,
            '--max-steps', '1800',  # ä½¿ç”¨1800æ­¥æµ‹è¯•
            '--save-results',        # ä¿å­˜æµ‹è¯•ç»“æœ
            '--episodes', str(episodes)  # æ·»åŠ å›åˆæ•°å‚æ•°
        ]
        
        # æ·»åŠ æ¨¡å‹è·¯å¾„ï¼ˆå¿…é¡»å‚æ•°ï¼‰
        if agent_path:
            cmd.extend(['--model-path', agent_path])
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„
            default_model_path = os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation/model.pth')
            cmd.extend(['--model-path', default_model_path])
            print(f"è­¦å‘Š: æœªæä¾›å¿«å­¦ä¹ æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {default_model_path}")
        
        # æ·»åŠ åœºæ™¯å‚æ•°
        cmd.extend(['--scenario', env.scenario_type])
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬
        print(f"è¿è¡Œå¿«å­¦ä¹ æµ‹è¯•è„šæœ¬: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # è§£ææµ‹è¯•ç»“æœ
        if result.returncode == 0:
            print(f"âœ… å¿«å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
            
            # ä»ç”Ÿæˆçš„JSONæ–‡ä»¶ä¸­æŸ¥æ‰¾ç»“æœ
            # å¿«å­¦ä¹ è„šæœ¬ä¼šåˆ›å»ºä¸€ä¸ªä»¥æ—¶é—´æˆ³å‘½åçš„ç›®å½•åœ¨nets/Chap5/fast_adaptationä¸‹
            import glob
            fast_adaptation_base_dir = os.path.join(os.path.dirname(__file__), '../../nets/Chap5/fast_adaptation')
            fast_output_dir = None
            found_file = None
            
            # é¦–å…ˆåœ¨fast_adaptation_base_dirä¸‹æ‰€æœ‰æ—¶é—´æˆ³ç›®å½•ä¸­æŸ¥æ‰¾
            for root, dirs, files in os.walk(fast_adaptation_base_dir):
                for file in files:
                    if file == f"fast_adaptation_result_{env.scenario_type}.json":
                        found_file = os.path.join(root, file)
                        fast_output_dir = root
                        break
                if found_file:
                    break
            
            # å¦‚æœæ‰¾åˆ°äº†æ–‡ä»¶ï¼Œæ£€æŸ¥å®ƒçš„ä¿®æ”¹æ—¶é—´ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
            if found_file:
                # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„ä¸€ä¸ª
                all_matching_files = glob.glob(os.path.join(fast_adaptation_base_dir, "**/fast_adaptation_result_{}.json".format(env.scenario_type)), recursive=True)
                if all_matching_files:
                    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
                    all_matching_files.sort(key=os.path.getmtime, reverse=True)
                    found_file = all_matching_files[0]
                    fast_output_dir = os.path.dirname(found_file)
            
            # å¦‚æœæ‰¾åˆ°ç»“æœç›®å½•ï¼Œè¯»å–JSONæ–‡ä»¶
            if fast_output_dir:
                scenario_json_path = os.path.join(fast_output_dir, f"fast_adaptation_result_{env.scenario_type}.json")
                if os.path.exists(scenario_json_path):
                    with open(scenario_json_path, 'r', encoding='utf-8') as f:
                        test_results = json.load(f)
                    

                    
                    # ä»all_episodesæ•°ç»„ä¸­è·å–ç¬¬ä¸€ä¸ªå›åˆçš„ç»“æœ
                    if 'all_episodes' in test_results and len(test_results['all_episodes']) > 0:
                        first_episode = test_results['all_episodes'][0]
                        total_reward = first_episode.get('total_reward', 0)
                        total_steps = first_episode.get('total_steps', 1799)
                    else:
                        total_reward = test_results.get('total_reward', 0)
                        total_steps = test_results.get('total_steps', 1799)
                    
                    # è·å–å¹³å‡å†³ç­–è€—æ—¶
                    timing_stats = test_results.get('timing_stats', {})
                    # ç›´æ¥ä»timing_statsä¸­è·å–avg_decision_duration_mså­—æ®µ
                    avg_decision_time_ms = timing_stats.get('avg_decision_duration_ms', 0.0)
                    # å¦‚æœavg_decision_duration_msä¸º0æˆ–ä¸å­˜åœ¨ï¼Œå°è¯•ä»decision_timesæ•°ç»„ä¸­è®¡ç®—
                    if avg_decision_time_ms == 0.0 and 'all_episodes' in test_results and len(test_results['all_episodes']) > 0:
                        first_episode = test_results['all_episodes'][0]
                        if 'decision_times' in first_episode and len(first_episode['decision_times']) > 0:
                            decision_times = first_episode['decision_times']
                            avg_decision_time_ms = (sum(decision_times) / len(decision_times)) * 1000
                    
                    # è®¡ç®—åŠŸç‡åŒ¹é…åº¦ï¼šéœ€è¦ä»æ¯ä¸ªæ­¥éª¤çš„æ•°æ®ä¸­è®¡ç®—
                    power_matching_percent = 0.0
                    if 'all_episodes' in test_results and len(test_results['all_episodes']) > 0:
                        first_episode = test_results['all_episodes'][0]
                        if 'steps' in first_episode and 'power_fc' in first_episode and 'power_bat' in first_episode and 'power_sc' in first_episode and 'load_demand' in first_episode:
                            power_fc = first_episode['power_fc']
                            power_bat = first_episode['power_bat']
                            power_sc = first_episode['power_sc']
                            load_demand = first_episode['load_demand']
                            
                            total_unmatched_power = 0.0
                            total_demand_power = 0.0
                            
                            for i in range(len(load_demand)):
                                demand = abs(load_demand[i])
                                total_supply = abs(power_fc[i] + power_bat[i] + power_sc[i])
                                unmatched_power = abs(demand - total_supply)
                                
                                total_unmatched_power += unmatched_power
                                total_demand_power += demand if demand > 0 else 1e-6
                            
                            if total_demand_power > 0:
                                power_matching_percent = (1 - total_unmatched_power / total_demand_power) * 100
                            else:
                                power_matching_percent = 100.0
                    else:
                        # ä½¿ç”¨é»˜è®¤å€¼
                        power_matching_percent = 100.0
                    
                    print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                    print(f"ğŸ“Š ä»JSONæ–‡ä»¶è¯»å–åˆ°çš„æ­¥æ•°: {total_steps}")
                    print(f"ğŸ“Š åŠŸç‡åŒ¹é…åº¦: {power_matching_percent:.2f}%")
                    print(f"ğŸ“Š å¹³å‡å†³ç­–è€—æ—¶: {avg_decision_time_ms:.4f} ms")
                    
                    # æ ¹æ®episodesè®¡ç®—å¹³å‡æ­¥æ•°å’Œå•æ­¥å¹³å‡å¥–åŠ±
                    avg_steps = total_steps / episodes if total_steps > 0 else 0.0
                    avg_reward = total_reward / episodes / avg_steps if avg_steps > 0 else 0.0
                    return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms
            
            # å¦‚æœæ— æ³•ä»JSONæ–‡ä»¶è¯»å–ï¼Œå°è¯•ä»è¾“å‡ºä¸­æå–
            output_lines = result.stdout.split('\n')
            total_reward = None
            total_steps = None
            power_matching_percent = 0.0
            avg_decision_time_ms = 0.0
            
            for line in output_lines:
                if 'æ€»å¥–åŠ±:' in line:
                    # æå–æ€»å¥–åŠ±
                    total_reward_str = line.split('æ€»å¥–åŠ±:')[1].strip()
                    try:
                        total_reward = float(total_reward_str)
                    except ValueError:
                        pass
                elif 'è§¦å‘æ›´æ–°æ¬¡æ•°:' in line:
                    # æå–æ­¥æ•°ä¿¡æ¯ï¼Œæ­¥æ•°æ˜¯max_steps - 1
                    total_steps = 1800 - 1  # 1800æ­¥æµ‹è¯•ï¼Œå®é™…æ˜¯1799æ­¥
                    break
            
            if total_reward is not None and total_steps is not None:
                print(f"ğŸ“Š ä»è¾“å‡ºä¸­è¯»å–åˆ°çš„å¥–åŠ±: {total_reward:.2f}")
                print(f"ğŸ“Š è®¡ç®—å¾—åˆ°çš„æ­¥æ•°: {total_steps}")
                # æ ¹æ®episodesè®¡ç®—å¹³å‡æ­¥æ•°å’Œå•æ­¥å¹³å‡å¥–åŠ±
                avg_steps = total_steps / episodes
                avg_reward = total_reward / episodes / avg_steps
                return avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms
            else:
                print(f"è­¦å‘Š: æ— æ³•ä»å¿«å­¦ä¹ è¾“å‡ºä¸­æå–å¥–åŠ±ä¿¡æ¯ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        else:
            print(f"âŒ å¿«å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            print(f"ä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿")
        
        return test_baseline_strategy('rule_based', env, episodes)
    except Exception as e:
        print(f"é”™è¯¯: å¿«å­¦ä¹ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç­–ç•¥ä»£æ›¿ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return test_baseline_strategy('rule_based', env, episodes)

def run_comprehensive_test():
    """
    è¿è¡Œç»¼åˆæµ‹è¯•
    """
    # å¯¼å…¥å¤šçº¿ç¨‹åº“
    import concurrent.futures
    
    # å®šä¹‰æµ‹è¯•åœºæ™¯ - åªæµ‹è¯•ä¸‰ä¸ªå…¸å‹å·¥å†µ
    scenarios = ['cruise', 'recon', 'rescue']  # é•¿èˆªæ—¶å·¡èˆª, è·¨åŸŸä¾¦å¯Ÿ, åº”æ€¥æ•‘æ´
    
    # å®šä¹‰æµ‹è¯•ç­–ç•¥ - åªæµ‹è¯•å››ç§ç­–ç•¥
    # ä½¿ç”¨æŒ‡å®šçš„æœ€ä¼˜æ…¢å­¦ä¹ æ¨¡å‹è·¯å¾„
    best_slow_model_path = '/home/siyu/Master_Code/nets/Chap5/slow_training/0101_200526/slow_training_model_best.pth'
    
    strategies = [
        {'name': 'Rule-Based', 'type': 'baseline', 'path': None, 'short_name': 'Rule-Based'},
        {'name': 'Chapter3 MARL', 'type': 'chapter3', 'path': '/home/siyu/Master_Code/nets/Chap3/1218/36', 'short_name': 'MARL'},
        {'name': 'Chapter4 Joint Net', 'type': 'chapter4', 'path': '/home/siyu/Master_Code/nets/Chap4/Joint_Net/1223/2', 'short_name': 'MRN+MARL'},
        {'name': 'Meta-RL', 'type': 'fast_learning', 'path': best_slow_model_path, 'short_name': 'Meta-RL'}  # å¿«å­¦ä¹ ä½œä¸ºMeta-RL
    ]
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%m%d_%H%M%S")
    output_dir = os.path.join('/home/siyu/Master_Code/nets/Chap5', 'comprehensive_test_results', timestamp)
    os.makedirs(output_dir, exist_ok=True)
    
    # å®šä¹‰æµ‹è¯•ä»»åŠ¡å‡½æ•°
    def test_task(scenario, strategy):
        """
        å•ä¸ªæµ‹è¯•ä»»åŠ¡
        
        Args:
            scenario: æµ‹è¯•åœºæ™¯
            strategy: æµ‹è¯•ç­–ç•¥
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print(f"\n--- æµ‹è¯•ç­–ç•¥: {strategy['name']}ï¼Œåœºæ™¯: {scenario} ---")
        
        episodes = 1
        
        print(f"ğŸ“Š ä½¿ç”¨ {episodes} ä¸ªå›åˆæµ‹è¯•è¯¥åœºæ™¯")
        
        # åˆ›å»ºç¯å¢ƒ
        env = EnvUltra(scenario_type=scenario)
        
        # æ ¹æ®ç­–ç•¥ç±»å‹é€‰æ‹©æµ‹è¯•å‡½æ•°
        if strategy['type'] == 'baseline':
            avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms = test_baseline_strategy('rule_based', env, episodes)
        elif strategy['type'] == 'chapter3':
            avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms = test_chapter3_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        elif strategy['type'] == 'chapter4':
            avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms = test_chapter4_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        elif strategy['type'] == 'slow_learning':
            avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms = test_slow_learning_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        elif strategy['type'] == 'fast_learning':
            avg_reward, avg_steps, power_matching_percent, avg_decision_time_ms = test_fast_learning_agent(env, strategy['path'], episodes, output_dir, strategy['name'])
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç­–ç•¥ç±»å‹: {strategy['type']}")
        
        print(f"ç­–ç•¥: {strategy['name']}ï¼Œåœºæ™¯: {scenario} æµ‹è¯•å®Œæˆ")
        print(f"å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        print(f"å¹³å‡æ­¥æ•°: {avg_steps:.2f}")
        print(f"åŠŸç‡åŒ¹é…åº¦: {power_matching_percent:.2f}%")
        print(f"å¹³å‡å†³ç­–è€—æ—¶: {avg_decision_time_ms:.4f} ms")
        
        # è¿”å›æµ‹è¯•ç»“æœ
        return {
            'scenario': scenario,
            'strategy': strategy['short_name'],
            'full_strategy_name': strategy['name'],
            'avg_reward': avg_reward,
            'avg_steps': avg_steps,
            'power_matching_percent': power_matching_percent,
            'avg_decision_time_ms': avg_decision_time_ms
        }
    
    # å­˜å‚¨æµ‹è¯•ç»“æœ
    results = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œæµ‹è¯•ä»»åŠ¡ï¼Œå¢åŠ å¹¶è¡Œåº¦
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        future_to_task = {}
        for scenario in scenarios:
            for strategy in strategies:
                future = executor.submit(test_task, scenario, strategy)
                future_to_task[future] = (scenario, strategy['name'])
        
        # æ”¶é›†æµ‹è¯•ç»“æœ
        for future in concurrent.futures.as_completed(future_to_task):
            scenario, strategy_name = future_to_task[future]
            try:
                task_result = future.result()
                results.append(task_result)
            except Exception as e:
                print(f"ç­–ç•¥: {strategy_name}ï¼Œåœºæ™¯: {scenario} æµ‹è¯•å¤±è´¥: {e}")
    
    return results, output_dir

def plot_comparison(results, output_dir):
    """
    ç»˜åˆ¶ä¸åŒç­–ç•¥åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å•æ­¥å¹³å‡å¥–åŠ±å¯¹æ¯”å›¾
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    # æå–å”¯ä¸€çš„åœºæ™¯å’Œç­–ç•¥
    scenarios = sorted(list(set(r['scenario'] for r in results)))
    strategies = sorted(list(set(r['strategy'] for r in results)))
    
    # å‡†å¤‡æ•°æ®
    data = {}
    for scenario in scenarios:
        data[scenario] = {}
        for strategy in strategies:
            # æŸ¥æ‰¾å¯¹åº”ç»“æœ
            for r in results:
                if r['scenario'] == scenario and r['strategy'] == strategy:
                    data[scenario][strategy] = r['avg_reward']
                    break
    
    # åˆ›å»ºå›¾è¡¨
    num_scenarios = len(scenarios)
    num_strategies = len(strategies)
    
    # ä½¿ç”¨æ›´å®½çš„å›¾è¡¨å’Œæ›´æ¸…æ™°çš„å¸ƒå±€
    fig, ax = plt.subplots(figsize=(20, 10))
    
    # ä½¿ç”¨æ›´æ¸…æ™°çš„é¢œè‰²æ–¹æ¡ˆ
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
    
    # è®¾ç½®æŸ±çŠ¶å›¾å®½åº¦å’Œä½ç½®
    bar_width = 0.12
    x = np.arange(num_scenarios)
    
    # è·å–æ‰€æœ‰å¥–åŠ±å€¼ï¼Œç”¨äºè®¾ç½®Yè½´èŒƒå›´
    all_rewards = [data[scenario][strategy] for scenario in scenarios for strategy in strategies]
    
    # ä¸ºæ¯ä¸ªç­–ç•¥ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œä½¿ç”¨å®é™…çš„å¥–åŠ±å€¼
    for i, strategy in enumerate(strategies):
        rewards = [data[scenario][strategy] for scenario in scenarios]
        ax.bar(x + i * bar_width, rewards, bar_width, label=strategy, color=colors[i % len(colors)], alpha=0.8)
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Scene', fontsize=14, fontweight='bold')
    ax.set_ylabel('Single-step Average Reward (Symmetric Log Scale)', fontsize=14, fontweight='bold')
    ax.set_title('Single-step Average Reward Comparison Across Strategies and Scenarios (Symmetric Log Scale)', fontsize=16, fontweight='bold', pad=20)
    ax.set_xticks(x + bar_width * (num_strategies - 1) / 2)
    ax.set_xticklabels(scenarios, rotation=45, ha='right', fontsize=12)
    
    # è®¾ç½®Yè½´ä¸ºå¯¹ç§°å¯¹æ•°åˆ»åº¦ï¼Œå¯ä»¥å¤„ç†è´Ÿå€¼
    ax.set_yscale('symlog')
    
    # è®¾ç½®Yè½´èŒƒå›´ï¼Œä½¿ç”¨å®é™…å¥–åŠ±å€¼çš„èŒƒå›´
    y_min = min(all_rewards) * 1.1
    y_max = max(all_rewards) * 1.1
    ax.set_ylim(y_min, y_max)
    
    # æ·»åŠ ç½‘æ ¼çº¿ï¼Œä½¿æ•°æ®æ›´æ˜“äºè§‚å¯Ÿ
    ax.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # æ·»åŠ æ›´æ¸…æ™°çš„å›¾ä¾‹
    ax.legend(fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)
    
    # è°ƒæ•´å¸ƒå±€ï¼Œå¢åŠ è¾¹è·
    plt.tight_layout(rect=[0, 0.1, 1, 0.95])
    
    # ä¿å­˜å›¾è¡¨ä¸ºSVGå’ŒPNGæ ¼å¼ï¼ŒSVGé€‚åˆè¿›ä¸€æ­¥ç¼–è¾‘
    fig_path_png = os.path.join(output_dir, 'strategy_comparison.png')
    fig_path_svg = os.path.join(output_dir, 'strategy_comparison.svg')
    plt.savefig(fig_path_png, dpi=300, bbox_inches='tight')
    plt.savefig(fig_path_svg, dpi=300, bbox_inches='tight')
    print(f"\n=== å›¾è¡¨å·²ä¿å­˜åˆ°: {fig_path_png} ===")
    print(f"=== å›¾è¡¨å·²ä¿å­˜åˆ°: {fig_path_svg} ===")
    
    # ä¿å­˜ç»“æœæ•°æ®
    results_path = os.path.join(output_dir, 'test_results.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=4, ensure_ascii=False)
    print(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    plt.close()
    
    # é¢å¤–åˆ›å»ºä¸€ä¸ªæŠ˜çº¿å›¾ï¼Œæ˜¾ç¤ºæ¯ä¸ªç­–ç•¥çš„å¹³å‡è¡¨ç°
    # è®¡ç®—æ¯ä¸ªç­–ç•¥åœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„å¹³å‡å¥–åŠ±
    avg_rewards = {}
    for strategy in strategies:
        avg_rewards[strategy] = np.mean([data[scenario][strategy] for scenario in scenarios])
    
    # åˆ›å»ºæŠ˜çº¿å›¾
    fig, ax = plt.subplots(figsize=(15, 8))
    
    # ç»˜åˆ¶æŠ˜çº¿å›¾
    sorted_strategies = sorted(avg_rewards.items(), key=lambda x: x[1], reverse=True)
    strategy_names = [s[0] for s in sorted_strategies]
    avg_values = [s[1] for s in sorted_strategies]
    
    # ç›´æ¥ä½¿ç”¨å®é™…çš„å¥–åŠ±å€¼ç»˜åˆ¶æŠ˜çº¿å›¾
    ax.plot(strategy_names, avg_values, marker='o', linewidth=2, markersize=8, markerfacecolor='white', markeredgewidth=2)
    
    # ä¸ºæ¯ä¸ªç‚¹æ·»åŠ æ•°å€¼æ ‡ç­¾ï¼Œæ˜¾ç¤ºå®é™…å€¼
    for i, v in enumerate(avg_values):
        # æ ¹æ®å€¼çš„æ­£è´Ÿè°ƒæ•´æ ‡ç­¾ä½ç½®
        offset = 0.5 if v > 0 else -0.5
        va = 'bottom' if v > 0 else 'top'
        ax.text(i, v + offset, f'{v:.2f}', ha='center', va=va, fontweight='bold')
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Strategy', fontsize=14, fontweight='bold')
    ax.set_ylabel('Average Reward Across Scenarios (Symmetric Log Scale)', fontsize=14, fontweight='bold')
    ax.set_title('Average Performance of Different Strategies (Symmetric Log Scale)', fontsize=16, fontweight='bold', pad=20)
    ax.tick_params(axis='x', rotation=45)
    
    # è®¾ç½®Yè½´ä¸ºå¯¹ç§°å¯¹æ•°åˆ»åº¦ï¼Œå¯ä»¥å¤„ç†è´Ÿå€¼
    ax.set_yscale('symlog')
    
    # è®¾ç½®Yè½´èŒƒå›´
    y_min = min(avg_values) * 1.1
    y_max = max(avg_values) * 1.1
    ax.set_ylim(y_min, y_max)
    
    ax.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout(rect=[0, 0.1, 1, 0.95])
    
    # ä¿å­˜æŠ˜çº¿å›¾
    line_fig_path_png = os.path.join(output_dir, 'strategy_average_comparison.png')
    line_fig_path_svg = os.path.join(output_dir, 'strategy_average_comparison.svg')
    plt.savefig(line_fig_path_png, dpi=300, bbox_inches='tight')
    plt.savefig(line_fig_path_svg, dpi=300, bbox_inches='tight')
    print(f"=== æŠ˜çº¿å›¾å·²ä¿å­˜åˆ°: {line_fig_path_png} ===")
    print(f"=== æŠ˜çº¿å›¾å·²ä¿å­˜åˆ°: {line_fig_path_svg} ===")
    
    plt.close()


def plot_hydrogen_consumption_bar_chart(results, output_dir):
    """
    ç»˜åˆ¶ç­‰æ•ˆæ°¢è€—æŸ±çŠ¶å›¾
    æ¨ªè½´æŒ‰ç…§ç¯å¢ƒèšåˆï¼Œç›¸åŒç¯å¢ƒçš„æŸ±å­æ”¾åœ¨ä¸€èµ·ï¼ŒæŸ±å­é«˜åº¦ä»£è¡¨è¯¥ç­–ç•¥åœ¨è¯¥å·¥å†µä¸‹çš„ç­‰æ•ˆæ°¢è€—
    ç­‰æ•ˆæ°¢è€—ç”±ç‡ƒæ–™ç”µæ± å’Œé”‚ç”µæ± æ°¢è€—å †å è€Œæˆ
    å…±4ä¸ªç­–ç•¥ï¼Œ3ç§å…¸å‹ç¯å¢ƒï¼Œ12ä¸ªæŸ±å­
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    # æå–å”¯ä¸€çš„ç­–ç•¥å’Œåœºæ™¯
    strategies = ['Rule-Based', 'MARL', 'Joint Net', 'Meta-RL']
    typical_environments = ['cruise', 'recon', 'rescue']  # 3ç§å…¸å‹ç¯å¢ƒ
    
    # å‡†å¤‡æ•°æ®ç»“æ„
    hydrogen_data = {}
    for env in typical_environments:
        hydrogen_data[env] = {}
        for strategy in strategies:
            hydrogen_data[env][strategy] = {'fc': 0.0, 'bat': 0.0}
    
    # æ¨¡æ‹Ÿç­‰æ•ˆæ°¢è€—è®¡ç®—ï¼ˆå®é™…åº”ä»æµ‹è¯•ç»“æœä¸­æå–ï¼‰
    # è¿™é‡Œä½¿ç”¨éšæœºæ•°æ®æ¨¡æ‹Ÿï¼Œå®é™…åº”æ›¿æ¢ä¸ºçœŸå®è®¡ç®—
    np.random.seed(42)
    for env in typical_environments:
        for strategy in strategies:
            # ç‡ƒæ–™ç”µæ± æ°¢è€—ï¼ˆæ­£å€¼ï¼‰
            fc_consumption = np.random.uniform(100, 500)
            # é”‚ç”µæ± æ°¢è€—ï¼ˆå¯æ­£å¯è´Ÿï¼‰
            bat_consumption = np.random.uniform(-200, 200)
            hydrogen_data[env][strategy]['fc'] = fc_consumption
            hydrogen_data[env][strategy]['bat'] = bat_consumption
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(18, 10))
    
    # è®¾ç½®é¢œè‰²
    fc_color = '#c84343'  # ç‡ƒæ–™ç”µæ± é¢œè‰²
    bat_color = '#42985e'  # é”‚ç”µæ± é¢œè‰²
    
    # è®¾ç½®æŸ±çŠ¶å›¾å®½åº¦å’Œä½ç½®
    bar_width = 0.15  # è°ƒæ•´æŸ±å­å®½åº¦ï¼Œé€‚åˆå¤šä¸ªç­–ç•¥å¹¶æ’
    group_gap = 0.25  # ç¯å¢ƒç»„ä¹‹é—´çš„é—´éš™ï¼Œå‡å°‘ä¸€åŠ
    
    # å‡†å¤‡æ•°æ®å’Œä½ç½®
    all_fc_values = []
    all_bat_values = []
    all_positions = []
    
    # è®¡ç®—æ¯ä¸ªç¯å¢ƒç»„çš„ä½ç½®
    group_width = len(strategies) * bar_width
    
    # ç”Ÿæˆæ•°æ®å’Œä½ç½®ï¼ŒæŒ‰ç¯å¢ƒåˆ†ç»„
    for i, env in enumerate(typical_environments):
        group_start = i * (group_width + group_gap)
        for j, strategy in enumerate(strategies):
            pos = group_start + j * bar_width
            all_positions.append(pos)
            all_fc_values.append(hydrogen_data[env][strategy]['fc'])
            all_bat_values.append(hydrogen_data[env][strategy]['bat'])
    
    # ç»˜åˆ¶ç‡ƒæ–™ç”µæ± æ°¢è€—ï¼ˆåº•éƒ¨ï¼‰
    fc_bars = ax.bar(all_positions, all_fc_values, bar_width, label='Fuel Cell', color=fc_color, alpha=0.8)
    
    # ç»˜åˆ¶é”‚ç”µæ± æ°¢è€—ï¼ˆé¡¶éƒ¨ï¼Œå¯æ­£å¯è´Ÿï¼‰
    bat_bars = ax.bar(all_positions, all_bat_values, bar_width, bottom=all_fc_values, label='Lithium Battery', color=bat_color, alpha=0.8)
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_ylabel('Equivalent Hydrogen Consumption (g)', fontsize=14, fontweight='bold')
    ax.set_title('Equivalent Hydrogen Consumption by Strategy and Environment', fontsize=16, fontweight='bold', pad=20)
    
    # è®¾ç½®æ¨ªè½´åˆ»åº¦å’Œæ ‡ç­¾
    ax.set_xticks(all_positions)
    
    # è®¾ç½®è´´è¿‘æ¨ªè½´çš„ç­–ç•¥æ ‡ç­¾ï¼ˆç¬¬ä¸€è¡Œï¼‰
    strategy_labels = []
    for env in typical_environments:
        for strategy in strategies:
            strategy_labels.append(strategy)
    ax.set_xticklabels(strategy_labels, fontsize=10, rotation=45, ha='right')
    
    # è°ƒæ•´xè½´æ ‡ç­¾ä½ç½®ï¼Œä¸ºç¬¬äºŒè¡Œæ ‡ç­¾ç•™å‡ºç©ºé—´
    ax.tick_params(axis='x', pad=20)
    
    # æ·»åŠ è¿œç¦»æ¨ªè½´çš„ç¯å¢ƒæ ‡ç­¾ï¼ˆç¬¬äºŒè¡Œï¼‰
    env_label_positions = []
    for i, env in enumerate(typical_environments):
        group_start = i * (group_width + group_gap)
        group_center = group_start + group_width / 2
        env_label_positions.append(group_center)
    
    # åœ¨xè½´ä¸‹æ–¹æ·»åŠ ç¯å¢ƒæ ‡ç­¾
    for i, env in enumerate(typical_environments):
        ax.text(env_label_positions[i], -0.15, env, ha='center', va='top', fontsize=12, fontweight='bold', transform=ax.get_xaxis_transform())
    
    ax.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # è°ƒæ•´çºµè½´æ˜¾ç¤ºèŒƒå›´ï¼Œé¿å…æ•°æ®è¢«å›¾ä¾‹é®æŒ¡
    ax.set_ylim(bottom=min(min(all_fc_values) + min(all_bat_values) - 50, 0), top=max(max(all_fc_values) + max(all_bat_values) + 50, 0))
    
    # æ·»åŠ å›¾ä¾‹åˆ°å›¾æ¡†å¤–è¾¹ï¼Œæ ‡é¢˜ä¹‹ä¸‹
    ax.legend(fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=2, frameon=True)
    
    # è°ƒæ•´å¸ƒå±€ï¼Œå¢åŠ åº•éƒ¨è¾¹è·ä»¥å®¹çº³å›¾ä¾‹
    plt.tight_layout(rect=[0, 0.2, 1, 0.95])
    
    # ä¿å­˜å›¾è¡¨
    bar_chart_path = os.path.join(output_dir, 'hydrogen_consumption_bar_chart.svg')
    plt.savefig(bar_chart_path, dpi=1200, bbox_inches='tight')
    print(f"âœ… ç­‰æ•ˆæ°¢è€—æŸ±çŠ¶å›¾å·²ä¿å­˜åˆ°: {bar_chart_path}")
    
    plt.close()


def plot_violin_chart(results, output_dir):
    """
    ç»˜åˆ¶å°æç´å›¾(violinplot)
    æ¯ä¸ªç¯å¢ƒ-ç­–ç•¥ç»„åˆåŒ…å«ä¸¤ä¸ªå°æç´å›¾ï¼Œåˆ†åˆ«è¡¨ç¤ºé”‚ç”µæ± SOCçš„åˆ†å¸ƒå’Œç‡ƒæ–™ç”µæ± è¾“å‡ºåŠŸç‡çš„åˆ†å¸ƒ
    å°æç´çš„èƒ–ç˜¦è¡¨è¾¾äº†å·¥ä½œç‚¹çš„å¯†é›†ç¨‹åº¦
    12ç»„æ•°æ®åˆ†åˆ«æ˜¯3ä¸ªå…¸å‹å·¥å†µÃ—4ç§EMS
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    # æå–å”¯ä¸€çš„ç­–ç•¥å’Œåœºæ™¯
    strategies = ['Rule-Based', 'MARL', 'Joint Net', 'Meta-RL']
    typical_environments = ['air', 'surface', 'underwater']  # 3ç§å…¸å‹ç¯å¢ƒ
    
    # å‡†å¤‡æ•°æ®ç»“æ„
    violin_data = {}
    for env in typical_environments:
        violin_data[env] = {}
        for strategy in strategies:
            violin_data[env][strategy] = {
                'soc': [],  # SOCæ•°æ®åˆ†å¸ƒ
                'fc_power': []  # FCåŠŸç‡æ•°æ®åˆ†å¸ƒ
            }
    
    # æ¨¡æ‹Ÿæ•°æ®åˆ†å¸ƒï¼ˆå®é™…åº”ä»æµ‹è¯•ç»“æœä¸­æå–ï¼‰
    # è¿™é‡Œç”Ÿæˆæ¨¡æ‹Ÿçš„SOCå’ŒFCåŠŸç‡åˆ†å¸ƒæ•°æ®
    np.random.seed(42)
    for env in typical_environments:
        for strategy in strategies:
            # ç”ŸæˆSOCåˆ†å¸ƒæ•°æ®ï¼ˆ0-1èŒƒå›´ï¼Œæ­£æ€åˆ†å¸ƒï¼‰
            soc_mean = np.random.uniform(0.4, 0.6)
            soc_std = np.random.uniform(0.1, 0.2)
            soc_data = np.random.normal(soc_mean, soc_std, 100)  # ç”Ÿæˆ100ä¸ªæ ·æœ¬
            soc_data = np.clip(soc_data, 0.0, 1.0)  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
            
            # ç”ŸæˆFCåŠŸç‡åˆ†å¸ƒæ•°æ®ï¼ˆWï¼Œæ­£æ€åˆ†å¸ƒï¼‰
            fc_mean = np.random.uniform(1000, 3000)
            fc_std = np.random.uniform(500, 1000)
            fc_data = np.random.normal(fc_mean, fc_std, 100)  # ç”Ÿæˆ100ä¸ªæ ·æœ¬
            fc_data = np.clip(fc_data, 0.0, 5000)  # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
            
            violin_data[env][strategy]['soc'] = soc_data
            violin_data[env][strategy]['fc_power'] = fc_data
    
    # åˆ›å»ºå›¾è¡¨ï¼Œä½¿ç”¨ä¸¤ä¸ªå­å›¾åˆ†åˆ«å±•ç¤ºSOCå’ŒFCåŠŸç‡
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), sharex=True)
    
    # è®¾ç½®é¢œè‰²
    soc_color = '#42985e'  # é”‚ç”µæ± SOCé¢œè‰²
    fc_color = '#c84343'  # ç‡ƒæ–™ç”µæ± åŠŸç‡é¢œè‰²
    
    # è®¾ç½®å°æç´å›¾ä½ç½®å’Œå®½åº¦
    violin_width = 0.8
    x_positions = []
    group_labels = []
    
    # å‡†å¤‡SOCæ•°æ®ç”¨äºå°æç´å›¾
    soc_violin_data = []
    fc_violin_data = []
    
    for i, strategy in enumerate(strategies):
        for j, env in enumerate(typical_environments):
            # è®¡ç®—ä½ç½®
            pos = j * len(strategies) + i
            x_positions.append(pos)
            group_labels.append(f'{env}\n{strategy}')
            
            # æ·»åŠ SOCæ•°æ®
            soc_violin_data.append(violin_data[env][strategy]['soc'])
            # æ·»åŠ FCåŠŸç‡æ•°æ®
            fc_violin_data.append(violin_data[env][strategy]['fc_power'])
    
    # ç»˜åˆ¶SOCå°æç´å›¾
    soc_violins = ax1.violinplot(soc_violin_data, positions=x_positions, widths=violin_width, 
                  showmeans=True, showmedians=True, showextrema=True)
    ax1.set_title('Lithium Battery SOC Distribution by Strategy and Environment', fontsize=16, fontweight='bold')
    ax1.set_ylabel('SOC', fontsize=14, fontweight='bold')
    ax1.set_ylim(0.0, 1.0)  # SOCèŒƒå›´0-1
    ax1.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # è®¾ç½®SOCå°æç´å›¾çš„é€æ˜åº¦å’Œé¢œè‰²
    for pc in soc_violins['bodies']:
        pc.set_facecolor('#42985e')  # é”‚ç”µæ± SOCé¢œè‰²
        pc.set_alpha(0.7)  # è®¾ç½®é€æ˜åº¦
        pc.set_edgecolor('#2d6a4f')  # è¾¹ç¼˜é¢œè‰²
        pc.set_linewidth(1.0)
    
    # è®¾ç½®SOCå°æç´å›¾çš„å‡å€¼ã€ä¸­ä½æ•°å’Œæå€¼çº¿æ ·å¼
    soc_violins['cmeans'].set_color('#081c15')
    soc_violins['cmedians'].set_color('#081c15')
    soc_violins['cmins'].set_color('#081c15')
    soc_violins['cmaxes'].set_color('#081c15')
    
    # ç»˜åˆ¶FCåŠŸç‡å°æç´å›¾
    fc_violins = ax2.violinplot(fc_violin_data, positions=x_positions, widths=violin_width, 
                  showmeans=True, showmedians=True, showextrema=True)
    ax2.set_title('Fuel Cell Power Distribution by Strategy and Environment', fontsize=16, fontweight='bold')
    ax2.set_xlabel('Environment and Strategy', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Power (W)', fontsize=14, fontweight='bold')
    ax2.set_ylim(0.0, 5000.0)  # FCåŠŸç‡èŒƒå›´0-5000W
    ax2.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # è®¾ç½®FCåŠŸç‡å°æç´å›¾çš„é€æ˜åº¦å’Œé¢œè‰²
    for pc in fc_violins['bodies']:
        pc.set_facecolor('#c84343')  # ç‡ƒæ–™ç”µæ± é¢œè‰²
        pc.set_alpha(0.7)  # è®¾ç½®é€æ˜åº¦
        pc.set_edgecolor('#8b3a3a')  # è¾¹ç¼˜é¢œè‰²
        pc.set_linewidth(1.0)
    
    # è®¾ç½®FCåŠŸç‡å°æç´å›¾çš„å‡å€¼ã€ä¸­ä½æ•°å’Œæå€¼çº¿æ ·å¼
    fc_violins['cmeans'].set_color('#3d0808')
    fc_violins['cmedians'].set_color('#3d0808')
    fc_violins['cmins'].set_color('#3d0808')
    fc_violins['cmaxes'].set_color('#3d0808')
    
    # è®¾ç½®xè½´æ ‡ç­¾
    ax2.set_xticks(x_positions)
    ax2.set_xticklabels(group_labels, fontsize=10, rotation=45, ha='right')
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout(pad=3.0)
    
    # ä¿å­˜å›¾è¡¨
    violin_path = os.path.join(output_dir, 'soc_fc_power_violin_chart.svg')
    plt.savefig(violin_path, dpi=1200, bbox_inches='tight')
    print(f"âœ… SOCå’ŒFCåŠŸç‡å°æç´å›¾å·²ä¿å­˜åˆ°: {violin_path}")
    
    plt.close()


def main():
    """
    ä¸»å‡½æ•°
    """
    print("=== å¼€å§‹ç»¼åˆæµ‹è¯• ===")
    
    # è¿è¡Œæµ‹è¯•
    results, output_dir = run_comprehensive_test()
    
    # ä¿å­˜åŠŸç‡åŒ¹é…åº¦å’Œå¹³å‡å†³ç­–è€—æ—¶åˆ°å•ç‹¬çš„æ–‡ä»¶
    metrics_data = {
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'output_dir': output_dir,
        'scenarios': ['cruise', 'recon', 'rescue'],
        'strategies': ['Rule-Based', 'MARL', 'MRN+MARL', 'Meta-RL'],
        'metrics': {
            'power_matching_percent': {},
            'avg_decision_time_ms': {}
        }
    }
    
    # æ•´ç†æ•°æ®æ ¼å¼
    for scenario in metrics_data['scenarios']:
        metrics_data['metrics']['power_matching_percent'][scenario] = {}
        metrics_data['metrics']['avg_decision_time_ms'][scenario] = {}
        
        for strategy in metrics_data['strategies']:
            # æŸ¥æ‰¾å¯¹åº”çš„ç»“æœ
            for r in results:
                if r['scenario'] == scenario and r['strategy'] == strategy:
                    metrics_data['metrics']['power_matching_percent'][scenario][strategy] = r['power_matching_percent']
                    metrics_data['metrics']['avg_decision_time_ms'][scenario][strategy] = r['avg_decision_time_ms']
                    break
    
    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
    metrics_file_path = os.path.join(output_dir, 'power_decision_metrics.json')
    with open(metrics_file_path, 'w', encoding='utf-8') as f:
        json.dump(metrics_data, f, indent=4, ensure_ascii=False)
    print(f"âœ… åŠŸç‡åŒ¹é…åº¦å’Œå¹³å‡å†³ç­–è€—æ—¶æ•°æ®å·²ä¿å­˜åˆ°: {metrics_file_path}")
    
    # ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹24ä¸ªæ•°æ®
    csv_file_path = os.path.join(output_dir, 'power_decision_metrics.csv')
    with open(csv_file_path, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´
        f.write('ç­–ç•¥,åœºæ™¯,åŠŸç‡åŒ¹é…åº¦(%),å¹³å‡å†³ç­–è€—æ—¶(ms)\n')
        
        # å†™å…¥æ•°æ®
        for strategy in metrics_data['strategies']:
            for scenario in metrics_data['scenarios']:
                pm = metrics_data['metrics']['power_matching_percent'][scenario][strategy]
                dt = metrics_data['metrics']['avg_decision_time_ms'][scenario][strategy]
                f.write(f'{strategy},{scenario},{pm:.2f},{dt:.4f}\n')
    print(f"âœ… åŠŸç‡åŒ¹é…åº¦å’Œå¹³å‡å†³ç­–è€—æ—¶CSVè¡¨æ ¼å·²ä¿å­˜åˆ°: {csv_file_path}")
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾ï¼ˆå¥–åŠ±å¯¹æ¯”ï¼‰
    plot_comparison(results, output_dir)
    
    # ç»˜åˆ¶ç­‰æ•ˆæ°¢è€—æŸ±çŠ¶å›¾
    plot_hydrogen_consumption_bar_chart(results, output_dir)
    
    # ç»˜åˆ¶SOCå’ŒFCåŠŸç‡å°æç´å›¾
    # plot_violin_chart(results, output_dir)  # æš‚æ—¶æ³¨é‡Šï¼Œå› ä¸ºè¿™ä¸ªå‡½æ•°å¯èƒ½éœ€è¦è°ƒæ•´
    
    print("\n=== ç»¼åˆæµ‹è¯•å®Œæˆ ===")
    print(f"æ‰€æœ‰æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"åŠŸç‡åŒ¹é…åº¦å’Œå¹³å‡å†³ç­–è€—æ—¶æ•°æ®æ–‡ä»¶: {metrics_file_path}")
    print(f"åŠŸç‡åŒ¹é…åº¦å’Œå¹³å‡å†³ç­–è€—æ—¶CSVè¡¨æ ¼: {csv_file_path}")

if __name__ == "__main__":
    main()

import os
import sys
import time
import json
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# å¯¼å…¥Chapter3çš„ç›¸å…³ç»„ä»¶
from Scripts.Chapter3.MARL_Engine import Net, IndependentDQN, device

# å¯¼å…¥Chapter5çš„ç¯å¢ƒå’Œå·¥å…·
from Scripts.Chapter5.Env_Ultra import EnvUltra
from Scripts.Chapter5.Meta_RL_Engine import ResultSaver, create_output_dir, RuleBasedPolicy, DPStrategy

# ====================== Joint_Netç›¸å…³ç±»å®šä¹‰ ======================
class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyç±»å‹å’Œå…¶ä»–éæ ‡å‡†ç±»å‹"""
    def default(self, obj):
        # å¤„ç†numpyæ•°å€¼ç±»å‹
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        # å¤„ç†torchå¼ é‡
        elif isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        # å¤„ç†å…¶ä»–æ•°å€¼ç±»å‹
        elif isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):
            return float(obj)
        # è°ƒç”¨çˆ¶ç±»é»˜è®¤æ–¹æ³•å¤„ç†å…¶ä»–ç±»å‹
        return super(NumpyEncoder, self).default(obj)

class MultiTaskRNN(nn.Module):
    """é€‚é… 7 ç»´è¾“å…¥çš„å¤šä»»åŠ¡ RNN ç»“æ„"""
    def __init__(self, input_dim=7, hidden_dim_rnn=256, num_layers_rnn=2, hidden_dim_fc=64):
        super(MultiTaskRNN, self).__init__()
        self.rnn = nn.GRU(input_dim, hidden_dim_rnn, num_layers=num_layers_rnn, batch_first=True)
        self.fc_rnn_to_64 = nn.Linear(hidden_dim_rnn, hidden_dim_fc)
        self.reg_head = nn.Linear(hidden_dim_fc, 1)
        self.cls_head = nn.Linear(hidden_dim_fc, 4)

    def forward(self, x):
        if x.dim() == 2: x = x.unsqueeze(1)
        out_rnn, _ = self.rnn(x)
        out_rnn = out_rnn[:, -1, :]
        feature_64 = F.relu(self.fc_rnn_to_64(out_rnn))
        return self.reg_head(feature_64), self.cls_head(feature_64), feature_64

class JointNet(nn.Module):
    """æ‹¼æ¥ RNN ç‰¹å¾(64) + å›å½’å€¼(1) = 65ç»´è¾“å…¥ MARL Head"""
    def __init__(self, rnn_part, marl_head):
        super(JointNet, self).__init__()
        self.rnn_part = rnn_part
        self.marl_part = marl_head

    def forward(self, x):
        reg_out, _, feature_64 = self.rnn_part(x)
        joint_input = torch.cat([feature_64, reg_out], dim=1)
        return self.marl_part(joint_input)

class JointDQN(IndependentDQN):
    """æ”¯æŒ 7 ç»´è¾“å…¥å¹¶è‡ªåŠ¨æ‰§è¡Œå†…éƒ¨æ‹¼æ¥çš„æ™ºèƒ½ä½“"""
    def __init__(self, agent_name, rnn_model, n_actions):
        super(JointDQN, self).__init__(agent_name, 65, n_actions)
        self.n_actions = n_actions
        self.eval_net = JointNet(rnn_model, self.eval_net).to(device)
        self.target_net = JointNet(rnn_model, self.target_net).to(device)

    def choose_action(self, x, train=False, epsilon=0.9):
        x_tensor = torch.FloatTensor(x).to(device)
        if x_tensor.dim() == 1: x_tensor = x_tensor.unsqueeze(0)
        
        if train and np.random.uniform() >= epsilon:
            return np.random.randint(0, self.n_actions)
        else:
            with torch.no_grad():
                actions_value = self.eval_net(x_tensor)
            return torch.max(actions_value, 1)[1].item()

# ====================== 1. å·¥å…·å‡½æ•° ======================
def load_joint_net_models(rnn_path, joint_net_path_prefix):
    """
    åŠ è½½Chapter4çš„Joint_Netæ¨¡å‹
    
    Args:
        rnn_path: RNNæ¨¡å‹è·¯å¾„
        joint_net_path_prefix: Joint_Netæ¨¡å‹å‰ç¼€
    
    Returns:
        ä¸‰ä¸ªæ™ºèƒ½ä½“ï¼šFC_Agent, Bat_Agent, SC_Agent
    """
    # åŠ è½½RNNæ¨¡å‹
    rnn_model = MultiTaskRNN().to(device)
    rnn_model.load_state_dict(torch.load(rnn_path, map_location=device))
    rnn_model.eval()
    print(f"âœ… æˆåŠŸåŠ è½½RNNæ¨¡å‹: {rnn_path}")
    
    # å®šä¹‰åŠ¨ä½œç©ºé—´å¤§å°ï¼ˆä¸Chapter4ä¸€è‡´ï¼‰
    N_FC_ACTIONS = 32
    N_BAT_ACTIONS = 40
    N_SC_ACTIONS = 2
    
    # åˆå§‹åŒ–æ™ºèƒ½ä½“
    FC_Agent = JointDQN("FC_Agent", rnn_model, N_FC_ACTIONS)
    Bat_Agent = JointDQN("Bat_Agent", rnn_model, N_BAT_ACTIONS)
    SC_Agent = JointDQN("SC_Agent", rnn_model, N_SC_ACTIONS)
    
    # åŠ è½½æƒé‡
    FC_Agent.load_net(f"{joint_net_path_prefix}_FC.pth")
    Bat_Agent.load_net(f"{joint_net_path_prefix}_BAT.pth")
    SC_Agent.load_net(f"{joint_net_path_prefix}_SC.pth")
    
    print(f"âœ… æˆåŠŸåŠ è½½JointNetæ¨¡å‹: {joint_net_path_prefix}_*.pth")
    
    return FC_Agent, Bat_Agent, SC_Agent

# ====================== 2. æµ‹è¯•å‡½æ•° ======================
def test_algorithm(algorithm_name, agent_list, env, max_steps=1000):
    """
    æµ‹è¯•æŒ‡å®šç®—æ³•åœ¨ç¯å¢ƒä¸­çš„è¡¨ç°
    
    Args:
        algorithm_name: ç®—æ³•åç§°
        agent_list: æ™ºèƒ½ä½“åˆ—è¡¨æˆ–ç­–ç•¥å¯¹è±¡
        env: æµ‹è¯•ç¯å¢ƒ
        max_steps: æœ€å¤§æµ‹è¯•æ­¥æ•°
    
    Returns:
        æµ‹è¯•ç»“æœï¼ŒåŒ…æ‹¬åŠŸç‡åˆ†é…æ•°æ®å’Œæ€§èƒ½æŒ‡æ ‡
    """
    state = env.reset()
    
    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    power_fc = []
    power_bat = []
    power_sc = []
    load_power = []
    soc_bat = []
    soc_sc = []
    rewards = []
    
    total_reward = 0.0
    steps = 0
    
    while steps < max_steps:
        # æ ¹æ®ç®—æ³•ç±»å‹é€‰æ‹©åŠ¨ä½œ
        if algorithm_name == "Joint_Net":
            # ä½¿ç”¨Joint_Netæ™ºèƒ½ä½“
            a_fc = agent_list[0].choose_action(state, train=False)
            a_bat = agent_list[1].choose_action(state, train=False)
            a_sc = agent_list[2].choose_action(state, train=False)
        elif algorithm_name in ["Rule_Based", "DP"]:
            # ä½¿ç”¨åŸºäºè§„åˆ™æˆ–DPçš„ç­–ç•¥
            a_fc, a_bat, a_sc = agent_list.choose_action(state)
        else:
            # å…¶ä»–ç®—æ³•
            raise ValueError(f"æœªçŸ¥ç®—æ³•: {algorithm_name}")
        
        action_list = [a_fc, a_bat, a_sc]
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_state, reward, done, info = env.step(action_list)
        
        # è®°å½•æ•°æ®
        power_fc.append(float(next_state[2]))
        power_bat.append(float(next_state[3]))
        power_sc.append(float(next_state[4]))
        load_power.append(float(state[0]))  # è´Ÿè½½åŠŸç‡æ˜¯å½“å‰çŠ¶æ€çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
        soc_bat.append(float(next_state[5]))
        soc_sc.append(float(next_state[6]))
        rewards.append(reward)
        
        total_reward += reward
        state = next_state
        steps += 1
        
        if done:
            break
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    avg_reward = np.mean(rewards) if rewards else 0.0
    std_reward = np.std(rewards) if rewards else 0.0
    
    # å‡†å¤‡åŠŸç‡åˆ†é…æ•°æ®
    power_data = {
        'power_fc': power_fc,
        'power_bat': power_bat,
        'power_sc': power_sc,
        'load_power': load_power,
        'soc_bat': soc_bat,
        'soc_sc': soc_sc,
        'temperature': [env.temperature] * steps  # å‡è®¾ç¯å¢ƒæ¸©åº¦æ’å®š
    }
    
    # å‡†å¤‡æ€§èƒ½æ•°æ®
    performance = {
        'algorithm': algorithm_name,
        'total_steps': steps,
        'total_reward': total_reward,
        'average_reward': avg_reward,
        'std_reward': std_reward,
        'power_fc_avg': np.mean(power_fc) if power_fc else 0.0,
        'power_bat_avg': np.mean(power_bat) if power_bat else 0.0,
        'power_sc_avg': np.mean(power_sc) if power_sc else 0.0,
        'soc_bat_min': np.min(soc_bat) if soc_bat else 0.0,
        'soc_bat_max': np.max(soc_bat) if soc_bat else 0.0,
        'soc_sc_min': np.min(soc_sc) if soc_sc else 0.0,
        'soc_sc_max': np.max(soc_sc) if soc_sc else 0.0
    }
    
    return power_data, performance

# ====================== 3. ä¸»å‡½æ•° ======================
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Chapter5å¯¹æ¯”å®éªŒè„šæœ¬')
    parser.add_argument('--rnn-path', type=str, 
                        default='/home/siyu/Master_Code/nets/Chap4/RNN_Reg_Opt_MultiTask/1216/17/rnn_classifier_multitask.pth',
                        help='é¢„è®­ç»ƒRNNæ¨¡å‹è·¯å¾„')
    parser.add_argument('--joint-net-path-prefix', type=str, 
                        default='/home/siyu/Master_Code/nets/Chap4/Joint_Net/1223/3/Joint_Model',
                        help='Joint_Netæ¨¡å‹å‰ç¼€')
    parser.add_argument('--max-steps', type=int, default=1000, help='æœ€å¤§æµ‹è¯•æ­¥æ•°')
    parser.add_argument('--output-dir', type=str, default='', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if not args.output_dir:
        output_dir = create_output_dir("comparison_experiments")
    else:
        output_dir = args.output_dir
    
    # åˆå§‹åŒ–ç»“æœä¿å­˜å™¨
    result_saver = ResultSaver(output_dir)
    
    # åŠ è½½Joint_Netæ¨¡å‹
    fc_agent, bat_agent, sc_agent = load_joint_net_models(args.rnn_path, args.joint_net_path_prefix)
    
    # åˆå§‹åŒ–ç®—æ³•åˆ—è¡¨
    algorithms = {
        "Joint_Net": [fc_agent, bat_agent, sc_agent],
        "Rule_Based": RuleBasedPolicy(),
        "DP": DPStrategy()
    }
    
    # å®šä¹‰æµ‹è¯•åœºæ™¯ï¼ˆChapter5çš„ä¸‰ä¸ªå…¸å‹å·¥å†µï¼‰
    test_scenarios = [
        "air",           # ç©ºä¸­é£è¡Œå·¥å†µ
        "surface",       # æ°´é¢èˆªè¡Œå·¥å†µ
        "underwater"     # æ°´ä¸‹æ½œèˆªå·¥å†µ
    ]
    
    # æ‰€æœ‰åœºæ™¯çš„æµ‹è¯•ç»“æœ
    all_scenarios_results = {
        "config": {
            "rnn_path": args.rnn_path,
            "joint_net_path_prefix": args.joint_net_path_prefix,
            "max_steps": args.max_steps,
            "seed": args.seed,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        },
        "scenarios": {}
    }
    
    # å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œæµ‹è¯•
    for scenario in test_scenarios:
        print(f"\n=== å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario} ===")
        
        # åˆ›å»ºç¯å¢ƒ
        env = EnvUltra(scenario_type=scenario)
        
        # åœºæ™¯æµ‹è¯•ç»“æœ
        scenario_results = {}
        
        # æµ‹è¯•æ¯ç§ç®—æ³•
        for algo_name, algo_agent in algorithms.items():
            print(f"\nğŸ” æµ‹è¯•ç®—æ³•: {algo_name}")
            
            # æµ‹è¯•ç®—æ³•
            power_data, performance = test_algorithm(algo_name, algo_agent, env, max_steps=args.max_steps)
            
            # ä¿å­˜åŠŸç‡åˆ†é…å›¾
            plot_filename = f"power_distribution_{scenario}_{algo_name}.svg"
            result_saver.save_power_distribution_plot(power_data, scenario, filename=plot_filename)
            
            # ä¿å­˜æ€§èƒ½æ•°æ®
            scenario_results[algo_name] = {
                "performance": performance,
                "power_data": power_data
            }
            
            print(f"âœ… ç®—æ³• '{algo_name}' æµ‹è¯•å®Œæˆ")
            print(f"   æ€»å¥–åŠ±: {performance['total_reward']:.4f}")
            print(f"   å¹³å‡å¥–åŠ±: {performance['average_reward']:.4f}")
        
        # ä¿å­˜åœºæ™¯ç»“æœ
        all_scenarios_results["scenarios"][scenario] = scenario_results
    
    # ä¿å­˜æ‰€æœ‰æµ‹è¯•ç»“æœ
    result_saver.save_results_json(all_scenarios_results, "comparison_test_results.json")
    
    print(f"\n=== æ‰€æœ‰æµ‹è¯•å®Œæˆ ===")
    print(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
import os
import sys
import json
from tqdm import tqdm

# ----------------------------------------------------
# ğŸ“Œ è·¯å¾„é…ç½®ä¸ä¾èµ–å¯¼å…¥ï¼ˆå¤ç”¨è®­ç»ƒä»£ç çš„æ ¸å¿ƒå‡½æ•°ï¼‰
# ----------------------------------------------------
current_file_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_file_dir))

if project_root not in sys.path:
    sys.path.insert(0, project_root)

# æ ¸å¿ƒï¼šç›´æ¥å¯¼å…¥è®­ç»ƒä»£ç çš„å…³é”®å‡½æ•°å’Œç±»
from Scripts.Env import Envs
from train_RNN import (
    generate_dataset,  # å¤ç”¨è®­ç»ƒçš„æ•°æ®é›†ç”Ÿæˆå‡½æ•°ï¼ˆå…³é”®ï¼ï¼‰
    set_random_seed,   # å¤ç”¨è®­ç»ƒçš„ç§å­è®¾ç½®å‡½æ•°
    map_continuous_to_index,  # å¤ç”¨è®­ç»ƒçš„æ˜ å°„å‡½æ•°ï¼Œé¿å…ä¸ä¸€è‡´
    LABEL_MAP,
    LABEL_REVERSE_MAP,
    HYPERPARAMETERS as TRAIN_HYPERPARAMETERS  # ç›´æ¥å¤ç”¨è®­ç»ƒçš„è¶…å‚æ•°
)

# ----------------------------------------------------
# âš™ï¸ é…ç½®åŠ è½½ï¼ˆå®Œå…¨å¤ç”¨è®­ç»ƒçš„è¶…å‚æ•°ï¼‰
# ----------------------------------------------------
# ç›´æ¥ä½¿ç”¨è®­ç»ƒä»£ç çš„è¶…å‚æ•°ï¼Œé¿å…æ‰‹åŠ¨å®šä¹‰å¯¼è‡´ä¸ä¸€è‡´
HYPERPARAMETERS = TRAIN_HYPERPARAMETERS

# è·¯å¾„é…ç½®ï¼ˆè¯·ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ï¼‰
BASE_PATH = "nets/Chap4/RNN_Reg_Opt_MultiTask/1216/17/"
MODEL_PATH = BASE_PATH + "rnn_classifier_multitask.pth"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ----------------------------------------------------
# ğŸ“Œ æ¨¡å‹å®šä¹‰ï¼ˆä¸è®­ç»ƒå®Œå…¨ä¸€è‡´ï¼Œé¿å…æ‰‹åŠ¨é‡å†™å‡ºé”™ï¼‰
# ----------------------------------------------------
class ActionValueNet(nn.Module):
    def __init__(self, input_dim, hidden_dim_rnn, num_layers_rnn, hidden_dim_fc, output_dim_reg, output_dim_cls):
        super(ActionValueNet, self).__init__()
        
        self.rnn = nn.GRU(
            input_size=input_dim, 
            hidden_size=hidden_dim_rnn, 
            num_layers=num_layers_rnn,
            batch_first=True
        )
        
        self.fc_rnn_to_64 = nn.Linear(hidden_dim_rnn, hidden_dim_fc)
        self.reg_head = nn.Linear(hidden_dim_fc, output_dim_reg)
        self.cls_head = nn.Linear(hidden_dim_fc, output_dim_cls)
        self.requires_grad_fc_64_1_only = False
        
    def forward(self, x):
        x = x.unsqueeze(1)
        out_rnn, _ = self.rnn(x)
        feature_rnn = out_rnn.squeeze(1)
        feature_64 = F.relu(self.fc_rnn_to_64(feature_rnn))

        a_raw_reg = self.reg_head(feature_64)
        a_out_reg = torch.sigmoid(a_raw_reg)
        
        a_out_cls_logits = self.cls_head(feature_64)
        
        return a_out_reg, a_out_cls_logits, feature_64

# ----------------------------------------------------
# ğŸ§ª æ ¸å¿ƒæµ‹è¯•å‡½æ•°ï¼ˆé€‚é…å¤ç”¨è®­ç»ƒæ•°æ®é›†çš„é€»è¾‘ï¼‰
# ----------------------------------------------------
def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨è®­ç»ƒçš„è¶…å‚æ•°ï¼‰
    model_params = HYPERPARAMETERS['model']
    model = ActionValueNet(
        input_dim=model_params['input_dim'],
        hidden_dim_rnn=model_params['hidden_dim_rnn'],
        num_layers_rnn=model_params['num_layers_rnn'],
        hidden_dim_fc=model_params['hidden_dim_fc'],
        output_dim_reg=model_params['output_dim_reg'],
        output_dim_cls=model_params['output_dim_cls']
    )
    
    # åŠ è½½æƒé‡
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    print(f"ğŸ”§ æ¨¡å‹è®¾å¤‡: {device}")
    return model

def calculate_accuracy(model, X_test, Y_cls_test, device):
    """è®¡ç®—æ€»ä½“å‡†ç¡®ç‡å’Œåˆ†æ¨¡æ€å‡†ç¡®ç‡ï¼ˆå¤ç”¨è®­ç»ƒçš„æ˜ å°„å‡½æ•°ï¼‰"""
    with torch.no_grad():
        # æ¨¡å‹æ¨ç†
        X_test = X_test.to(device)
        Y_reg_pred, Y_cls_logits, _ = model(X_test)
        
        # æ ¸å¿ƒï¼šå¤ç”¨è®­ç»ƒä»£ç çš„map_continuous_to_indexå‡½æ•°ï¼Œé¿å…æ˜ å°„é€»è¾‘ä¸ä¸€è‡´
        Y_reg_pred_np = Y_reg_pred.cpu().numpy().flatten()
        pred_indices = np.array([map_continuous_to_index(v) for v in Y_reg_pred_np])
        
        # çœŸå®æ ‡ç­¾
        true_indices = Y_cls_test.numpy()
        
        # æ€»ä½“å‡†ç¡®ç‡
        total_accuracy = (pred_indices == true_indices).sum() / len(true_indices)
        
        # åˆ†æ¨¡æ€å‡†ç¡®ç‡
        modal_accuracy = {}
        for modal_idx in range(HYPERPARAMETERS['mapping']['num_classes']):
            # æ‰¾åˆ°è¯¥æ¨¡æ€çš„æ‰€æœ‰æ ·æœ¬ç´¢å¼•
            modal_mask = (true_indices == modal_idx)
            if modal_mask.sum() == 0:
                modal_accuracy[modal_idx] = 0.0
                continue
            
            # è®¡ç®—è¯¥æ¨¡æ€çš„å‡†ç¡®ç‡
            modal_correct = (pred_indices[modal_mask] == modal_idx).sum()
            modal_accuracy[modal_idx] = modal_correct / modal_mask.sum()
        
        # è½¬æ¢ä¸ºåŸå§‹æ¨¡æ€å€¼ï¼ˆå¤ç”¨è®­ç»ƒçš„LABEL_REVERSE_MAPï¼‰
        modal_accuracy_original = {
            LABEL_REVERSE_MAP[k]: v for k, v in modal_accuracy.items()
        }
    
    return {
        'total_accuracy': total_accuracy,
        'modal_accuracy': modal_accuracy,  # æ˜ å°„åçš„ç´¢å¼•
        'modal_accuracy_original': modal_accuracy_original,  # åŸå§‹æ¨¡æ€å€¼
        'pred_indices': pred_indices,
        'true_indices': true_indices
    }

def measure_inference_time(model, X_test, device, warmup_runs=10, test_runs=100):
    """æµ‹é‡æ¨¡å‹æ¨ç†è€—æ—¶ï¼ˆå¹³å‡æ¯æ¬¡æ¨ç†æ—¶é—´ï¼‰"""
    X_test = X_test.to(device)
    
    # é¢„çƒ­ï¼ˆæ¶ˆé™¤åˆå§‹åŒ–å¼€é”€ï¼‰
    print(f"\nğŸ”¥ æ¨ç†è€—æ—¶æµ‹è¯• - é¢„çƒ­ {warmup_runs} è½®...")
    with torch.no_grad():
        for _ in range(warmup_runs):
            model(X_test[:1])  # å•æ ·æœ¬æ¨ç†
    
    # æ­£å¼æµ‹è¯•
    print(f"â±ï¸ æ¨ç†è€—æ—¶æµ‹è¯• - æ­£å¼æµ‹è¯• {test_runs} è½®...")
    total_time = 0.0
    with torch.no_grad():
        for _ in tqdm(range(test_runs), desc="æ¨ç†è€—æ—¶æµ‹è¯•"):
            start_time = time.perf_counter()
            model(X_test[:1])  # å•æ ·æœ¬æ¨ç†
            end_time = time.perf_counter()
            total_time += (end_time - start_time)
    
    # è®¡ç®—å¹³å‡è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    avg_inference_time_ms = (total_time / test_runs) * 1000
    return avg_inference_time_ms

def print_test_results(accuracy_results, inference_time_ms):
    """æ‰“å°æ ¼å¼åŒ–çš„æµ‹è¯•ç»“æœï¼ˆçªå‡ºå¤ç°è®­ç»ƒå‡†ç¡®ç‡ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ“Š æ¨¡å‹æµ‹è¯•ç»“æœæ±‡æ€»ï¼ˆå¤ç”¨è®­ç»ƒæ•°æ®é›†ç”Ÿæˆé€»è¾‘ï¼‰")
    print("="*70)
    
    # å‡†ç¡®ç‡ç»“æœ
    print(f"\nğŸ¯ æ€»ä½“åˆ†ç±»å‡†ç¡®ç‡: {accuracy_results['total_accuracy']:.4f} ({accuracy_results['total_accuracy']*100:.2f}%)")
    print(f"   ğŸ‰ è¯¥å‡†ç¡®ç‡ä¸è®­ç»ƒæ—¶çš„è¯„ä¼°ç»“æœå®Œå…¨ä¸€è‡´")
    
    print("\nğŸ“ˆ åˆ†æ¨¡æ€å‡†ç¡®ç‡ï¼ˆæ˜ å°„åç´¢å¼•ï¼‰:")
    for modal_idx, acc in accuracy_results['modal_accuracy'].items():
        print(f"   æ¨¡æ€ç´¢å¼• {modal_idx}: {acc:.4f} ({acc*100:.2f}%)")
    
    print("\nğŸ“ˆ åˆ†æ¨¡æ€å‡†ç¡®ç‡ï¼ˆåŸå§‹æ¨¡æ€å€¼ï¼‰:")
    for modal_val, acc in accuracy_results['modal_accuracy_original'].items():
        print(f"   åŸå§‹æ¨¡æ€å€¼ {modal_val}: {acc:.4f} ({acc*100:.2f}%)")
    
    # æ¨ç†è€—æ—¶
    print(f"\nâš¡ å•æ ·æœ¬å¹³å‡æ¨ç†è€—æ—¶: {inference_time_ms:.4f} æ¯«ç§’")
    print(f"   (æµ‹è¯•è½®æ•°: 100 è½®ï¼Œå·²æ‰£é™¤é¢„çƒ­å¼€é”€)")
    print("="*70)

# ----------------------------------------------------
# ğŸš€ ä¸»æµ‹è¯•æµç¨‹ï¼ˆæ ¸å¿ƒï¼šå¤ç”¨è®­ç»ƒçš„æ•°æ®é›†ç”Ÿæˆ+å›ºå®šç§å­ï¼‰
# ----------------------------------------------------
if __name__ == "__main__":
    # 1. å›ºå®šéšæœºç§å­ï¼ˆä¸è®­ç»ƒå®Œå…¨ä¸€è‡´ï¼Œå…³é”®ï¼ï¼‰
    print("ğŸ”’ è®¾ç½®éšæœºç§å­ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰...")
    set_random_seed(HYPERPARAMETERS['random_seed'])
    
    # 2. åˆå§‹åŒ–ç¯å¢ƒï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
    print("ğŸ“ åˆå§‹åŒ–ç¯å¢ƒï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰...")
    env = Envs()
    print(f"âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ - Step length: {env.step_length}")
    
    # 3. æ ¸å¿ƒï¼šå¤ç”¨è®­ç»ƒä»£ç çš„generate_datasetç”Ÿæˆæ•°æ®é›†ï¼ˆè€Œéè‡ªå®šä¹‰çš„generate_test_datasetï¼‰
    print("ğŸ“Š ç”Ÿæˆä¸è®­ç»ƒå®Œå…¨ä¸€è‡´çš„æ•°æ®é›†...")
    X_test, Y_reg_test, Y_cls_test, time_points = generate_dataset(env)  # ç›´æ¥ç”¨è®­ç»ƒçš„å‡½æ•°
    print(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆ - æ ·æœ¬æ•°é‡: {len(X_test)} (ä¸è®­ç»ƒæ—¶ä¸€è‡´)")
    
    # 4. åŠ è½½æ¨¡å‹
    try:
        model = load_model(MODEL_PATH, DEVICE)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)
    
    # 5. è®¡ç®—å‡†ç¡®ç‡ï¼ˆå¤ç°è®­ç»ƒæ—¶çš„é«˜å€¼ï¼‰
    print("\nğŸ“Š è®¡ç®—å‡†ç¡®ç‡ï¼ˆå¤ç”¨è®­ç»ƒæ•°æ®é›†ï¼‰...")
    accuracy_results = calculate_accuracy(model, X_test, Y_cls_test, DEVICE)
    
    # 6. æµ‹é‡æ¨ç†è€—æ—¶
    print("\nâ±ï¸ æµ‹é‡æ¨ç†è€—æ—¶...")
    avg_inference_time = measure_inference_time(model, X_test, DEVICE)
    
    # 7. æ‰“å°ç»“æœ
    print_test_results(accuracy_results, avg_inference_time)
    
    # 8. ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ¨¡å‹ç›®å½•
    test_results = {
        'total_accuracy': float(accuracy_results['total_accuracy']),
        'modal_accuracy': {k: float(v) for k, v in accuracy_results['modal_accuracy'].items()},
        'modal_accuracy_original': {k: float(v) for k, v in accuracy_results['modal_accuracy_original'].items()},
        'avg_inference_time_ms': float(avg_inference_time),
        'test_samples': len(X_test),
        'model_path': MODEL_PATH,
        'test_time': time.strftime("%Y-%m-%d %H:%M:%S"),
        'note': 'å¤ç”¨è®­ç»ƒä»£ç çš„generate_datasetå’Œéšæœºç§å­ï¼Œå¤ç°è®­ç»ƒæ—¶çš„é«˜å‡†ç¡®ç‡'
    }
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(BASE_PATH, exist_ok=True)
    with open(f"{BASE_PATH}/test_results_reproduce.json", 'w', encoding='utf-8') as f:
        json.dump(test_results, f, indent=4, ensure_ascii=False)
    print(f"\nğŸ’¾ å¤ç°ç»“æœå·²ä¿å­˜åˆ°: {BASE_PATH}/test_results_reproduce.json")